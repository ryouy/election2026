{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZm86ScmMOLqM4wdRGVWq7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryouy/election2026/blob/main/2026_Election_Yomiuri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 候補者詳細URLを収集"
      ],
      "metadata": {
        "id": "c31I68LHIK0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U9zx3RwvEdk",
        "outputId": "4516abf9-9700-48e3-ce70-059081e6d878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d3c27c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526b29bf-65e8-4706-d5dc-35b0c6e3cef3"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import re # Import regex module\n",
        "\n",
        "def get_prefecture_pages(main_url):\n",
        "    try:\n",
        "        response = requests.get(main_url)\n",
        "        response.raise_for_status()  # Check for HTTP errors\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        prefecture_data = []\n",
        "        # Regex to match prefecture-specific pages like 'https://www.yomiuri.co.jp/election/shugiin/YA01XXXXXX000/'\n",
        "        # The (0[1-9]|[1-3][0-9]|4[0-7]) part matches numbers from 01 to 47 for prefectures.\n",
        "        prefecture_pattern = r'^https://www.yomiuri.co.jp/election/shugiin/YA(0[1-9]|[1-3][0-9]|4[0-7])XXXXXX000/$'\n",
        "\n",
        "        all_links = soup.find_all('a', href=True)\n",
        "\n",
        "        for link_tag in all_links:\n",
        "            absolute_link = urljoin(main_url, link_tag.get('href'))\n",
        "            # Check if the link matches the prefecture pattern\n",
        "            if re.match(prefecture_pattern, absolute_link):\n",
        "                prefecture_name = link_tag.get_text(strip=True)\n",
        "                if prefecture_name: # Ensure there's actual text for the prefecture name\n",
        "                    prefecture_data.append({'prefecture_name': prefecture_name, 'prefecture_url': absolute_link})\n",
        "\n",
        "        return prefecture_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for {main_url}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during parsing {main_url}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Main URL for the Yomiuri Shimbun election page\n",
        "main_election_url = 'https://www.yomiuri.co.jp/election/shugiin/'\n",
        "\n",
        "# Call the function to get prefecture pages\n",
        "prefecture_pages = get_prefecture_pages(main_election_url)\n",
        "\n",
        "# Print the results to verify\n",
        "if prefecture_pages:\n",
        "    print(f\"Found {len(prefecture_pages)} prefecture pages.\")\n",
        "    print(\"First 5 entries:\")\n",
        "    for i, item in enumerate(prefecture_pages[:5]):\n",
        "        print(f\"  {i+1}. Name: {item['prefecture_name']}, URL: {item['prefecture_url']}\")\n",
        "else:\n",
        "    print(f\"No prefecture pages found on {main_election_url}.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 prefecture pages.\n",
            "First 5 entries:\n",
            "  1. Name: #選挙・東京, URL: https://www.yomiuri.co.jp/election/shugiin/YA13XXXXXX000/\n",
            "  2. Name: 北海道, URL: https://www.yomiuri.co.jp/election/shugiin/YA01XXXXXX000/\n",
            "  3. Name: 青森, URL: https://www.yomiuri.co.jp/election/shugiin/YA02XXXXXX000/\n",
            "  4. Name: 岩手, URL: https://www.yomiuri.co.jp/election/shugiin/YA03XXXXXX000/\n",
            "  5. Name: 宮城, URL: https://www.yomiuri.co.jp/election/shugiin/YA04XXXXXX000/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57aa333e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80a4f15-d30b-48d0-df06-0748fb36cc68"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import re # Import regex module\n",
        "\n",
        "def get_candidates_for_prefecture(prefecture_url):\n",
        "    try:\n",
        "        response = requests.get(prefecture_url)\n",
        "        response.raise_for_status()  # Check for HTTP errors\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        candidate_data = []\n",
        "        # Regex to match candidate-specific pages within a prefecture, e.g., 'https://www.yomiuri.co.jp/election/shugiin/2026/YA01XXXXXX000/135847/'\n",
        "        # The \\d+ matches one or more digits for the unique candidate ID.\n",
        "        # The prefecture code (e.g., 01 for Hokkaido) is dynamically inserted into the pattern using string formatting.\n",
        "        # Extract the prefecture code from the prefecture_url for accurate matching.\n",
        "        prefecture_code_match = re.search(r'YA(0[1-9]|[1-3][0-9]|4[0-7])XXXXXX000', prefecture_url)\n",
        "        if not prefecture_code_match:\n",
        "            print(f\"Could not extract prefecture code from URL: {prefecture_url}\")\n",
        "            return []\n",
        "        prefecture_code = prefecture_code_match.group(1)\n",
        "\n",
        "        candidate_pattern = rf'^https://www.yomiuri.co.jp/election/shugiin/2026/YA{prefecture_code}XXXXXX000/\\d+/$'\n",
        "\n",
        "        all_links = soup.find_all('a', href=True)\n",
        "\n",
        "        for link_tag in all_links:\n",
        "            absolute_link = urljoin(prefecture_url, link_tag.get('href'))\n",
        "            # Check if the link matches the candidate pattern\n",
        "            if re.match(candidate_pattern, absolute_link):\n",
        "                candidate_name_full = link_tag.get_text(strip=True)\n",
        "                # The name might include age, party, etc. Try to extract just the name if possible.\n",
        "                # A simple heuristic: take the first part before the age or party info.\n",
        "                name_match = re.match(r'([\\w\\s\\u3000\\u4e00-\\u9fff]+)\\d+歳', candidate_name_full)\n",
        "                candidate_name = name_match.group(1).strip() if name_match else candidate_name_full\n",
        "\n",
        "                if candidate_name and candidate_name != '#選挙・茨城': # Filter out the initial non-candidate link if it appears as a name\n",
        "                    candidate_data.append({'candidate_name': candidate_name, 'candidate_url': absolute_link})\n",
        "\n",
        "        # Remove duplicate entries based on candidate_url to avoid redundant articles.\n",
        "        unique_candidate_data = []\n",
        "        seen_urls = set()\n",
        "        for item in candidate_data:\n",
        "            if item['candidate_url'] not in seen_urls:\n",
        "                unique_candidate_data.append(item)\n",
        "                seen_urls.add(item['candidate_url'])\n",
        "\n",
        "        return unique_candidate_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for {prefecture_url}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during parsing {prefecture_url}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Example usage for one prefecture to verify the function (e.g., Hokkaido, which is the second entry in prefecture_pages)\n",
        "# Ensure prefecture_pages is available from the previous cell's execution\n",
        "if 'prefecture_pages' in globals() and prefecture_pages:\n",
        "    # Using the second entry from prefecture_pages (index 1) which is Hokkaido\n",
        "    hokkaido_entry = prefecture_pages[1]\n",
        "    hokkaido_name = hokkaido_entry['prefecture_name']\n",
        "    hokkaido_url = hokkaido_entry['prefecture_url']\n",
        "\n",
        "    print(f\"\\n--- Scraping candidates for {hokkaido_name} ({hokkaido_url}) ---\")\n",
        "    hokkaido_candidates = get_candidates_for_prefecture(hokkaido_url)\n",
        "\n",
        "    if hokkaido_candidates:\n",
        "        print(f\"Found {len(hokkaido_candidates)} candidates for {hokkaido_name}.\")\n",
        "        print(\"First 5 candidates:\")\n",
        "        for i, candidate in enumerate(hokkaido_candidates[:5]):\n",
        "            print(f\"  {i+1}. Name: {candidate['candidate_name']}, URL: {candidate['candidate_url']}\")\n",
        "    else:\n",
        "        print(f\"No candidates found for {hokkaido_name}.\")\n",
        "else:\n",
        "    print(\"prefecture_pages variable not found or is empty. Please run the previous cell.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Scraping candidates for 北海道 (https://www.yomiuri.co.jp/election/shugiin/YA01XXXXXX000/) ---\n",
            "Found 38 candidates for 北海道.\n",
            "First 5 candidates:\n",
            "  1. Name: 道下　大樹5, URL: https://www.yomiuri.co.jp/election/shugiin/2026/YA01XXXXXX000/135847/\n",
            "  2. Name: 臼木　秀剛4, URL: https://www.yomiuri.co.jp/election/shugiin/2026/YA01XXXXXX000/137660/\n",
            "  3. Name: 森　英士4, URL: https://www.yomiuri.co.jp/election/shugiin/2026/YA01XXXXXX000/138866/\n",
            "  4. Name: 加藤　貴弘4, URL: https://www.yomiuri.co.jp/election/shugiin/2026/YA01XXXXXX000/136367/\n",
            "  5. Name: 加納　千津子5, URL: https://www.yomiuri.co.jp/election/shugiin/2026/YA01XXXXXX000/139207/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf1337a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0f089b-d00c-4e4c-9656-e34f5bd9c6d9"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def save_candidates_to_json(prefecture_name, candidates_data, base_dir='prefecture_data'):\n",
        "    \"\"\"\n",
        "    Creates a directory for the prefecture and saves candidate data to a JSON file.\n",
        "    \"\"\"\n",
        "    prefecture_dir = os.path.join(base_dir, prefecture_name)\n",
        "    os.makedirs(prefecture_dir, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(prefecture_dir, f\"{prefecture_name}_candidates.json\")\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(candidates_data, f, ensure_ascii=False, indent=4)\n",
        "    return len(candidates_data)\n",
        "\n",
        "\n",
        "# Initialize counters\n",
        "total_prefectures_processed = 0\n",
        "total_candidates_saved = 0\n",
        "all_scraped_data = {}\n",
        "\n",
        "# Ensure prefecture_pages is available from previous cells\n",
        "if 'prefecture_pages' in globals() and prefecture_pages:\n",
        "    print(f\"\\nProcessing candidates for {len(prefecture_pages)} prefectures...\")\n",
        "    for prefecture_entry in prefecture_pages:\n",
        "        prefecture_name = prefecture_entry['prefecture_name']\n",
        "        prefecture_url = prefecture_entry['prefecture_url']\n",
        "\n",
        "        # Skip any entry where the prefecture name starts with '#'\n",
        "        if prefecture_name.startswith('#'):\n",
        "            print(f\"Skipping non-prefecture entry: {prefecture_name}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  Scraping candidates for {prefecture_name}...\")\n",
        "        candidates = get_candidates_for_prefecture(prefecture_url)\n",
        "\n",
        "        if candidates:\n",
        "            candidates_count = save_candidates_to_json(prefecture_name, candidates)\n",
        "            total_prefectures_processed += 1\n",
        "            total_candidates_saved += candidates_count\n",
        "            all_scraped_data[prefecture_name] = candidates # Store for potential future use or summary\n",
        "            print(f\"    Saved {candidates_count} candidates for {prefecture_name}.\")\n",
        "        else:\n",
        "            print(f\"    No candidates found or failed to scrape for {prefecture_name}.\")\n",
        "\n",
        "    print(f\"\\n--- Summary ---\")\n",
        "    print(f\"Total prefectures processed: {total_prefectures_processed}\")\n",
        "    print(f\"Total candidate entries saved: {total_candidates_saved}\")\n",
        "else:\n",
        "    print(\"prefecture_pages variable not found or is empty. Please ensure previous steps ran successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing candidates for 105 prefectures...\n",
            "Skipping non-prefecture entry: #選挙・東京\n",
            "  Scraping candidates for 北海道...\n",
            "    Saved 38 candidates for 北海道.\n",
            "  Scraping candidates for 青森...\n",
            "    Saved 11 candidates for 青森.\n",
            "  Scraping candidates for 岩手...\n",
            "    Saved 10 candidates for 岩手.\n",
            "  Scraping candidates for 宮城...\n",
            "    Saved 21 candidates for 宮城.\n",
            "  Scraping candidates for 秋田...\n",
            "    Saved 10 candidates for 秋田.\n",
            "  Scraping candidates for 山形...\n",
            "    Saved 10 candidates for 山形.\n",
            "  Scraping candidates for 福島...\n",
            "    Saved 15 candidates for 福島.\n",
            "  Scraping candidates for 茨城...\n",
            "    Saved 23 candidates for 茨城.\n",
            "  Scraping candidates for 栃木...\n",
            "    Saved 20 candidates for 栃木.\n",
            "  Scraping candidates for 群馬...\n",
            "    Saved 17 candidates for 群馬.\n",
            "  Scraping candidates for 埼玉...\n",
            "    Saved 55 candidates for 埼玉.\n",
            "  Scraping candidates for 東京...\n",
            "    Saved 154 candidates for 東京.\n",
            "  Scraping candidates for 千葉...\n",
            "    Saved 52 candidates for 千葉.\n",
            "  Scraping candidates for 神奈川...\n",
            "    Saved 70 candidates for 神奈川.\n",
            "  Scraping candidates for 山梨...\n",
            "    Saved 6 candidates for 山梨.\n",
            "  Scraping candidates for 新潟...\n",
            "    Saved 19 candidates for 新潟.\n",
            "  Scraping candidates for 富山...\n",
            "    Saved 10 candidates for 富山.\n",
            "  Scraping candidates for 石川...\n",
            "    Saved 10 candidates for 石川.\n",
            "  Scraping candidates for 福井...\n",
            "    Saved 6 candidates for 福井.\n",
            "  Scraping candidates for 長野...\n",
            "    Saved 16 candidates for 長野.\n",
            "  Scraping candidates for 岐阜...\n",
            "    Saved 20 candidates for 岐阜.\n",
            "  Scraping candidates for 静岡...\n",
            "    Saved 26 candidates for 静岡.\n",
            "  Scraping candidates for 愛知...\n",
            "    Saved 68 candidates for 愛知.\n",
            "  Scraping candidates for 三重...\n",
            "    Saved 14 candidates for 三重.\n",
            "  Scraping candidates for 滋賀...\n",
            "    Saved 13 candidates for 滋賀.\n",
            "  Scraping candidates for 京都...\n",
            "    Saved 27 candidates for 京都.\n",
            "  Scraping candidates for 大阪...\n",
            "    Saved 84 candidates for 大阪.\n",
            "  Scraping candidates for 兵庫...\n",
            "    Saved 53 candidates for 兵庫.\n",
            "  Scraping candidates for 奈良...\n",
            "    Saved 11 candidates for 奈良.\n",
            "  Scraping candidates for 和歌山...\n",
            "    Saved 9 candidates for 和歌山.\n",
            "  Scraping candidates for 鳥取...\n",
            "    Saved 7 candidates for 鳥取.\n",
            "  Scraping candidates for 島根...\n",
            "    Saved 8 candidates for 島根.\n",
            "  Scraping candidates for 岡山...\n",
            "    Saved 15 candidates for 岡山.\n",
            "  Scraping candidates for 広島...\n",
            "    Saved 25 candidates for 広島.\n",
            "  Scraping candidates for 山口...\n",
            "    Saved 10 candidates for 山口.\n",
            "  Scraping candidates for 徳島...\n",
            "    Saved 8 candidates for 徳島.\n",
            "  Scraping candidates for 香川...\n",
            "    Saved 10 candidates for 香川.\n",
            "  Scraping candidates for 愛媛...\n",
            "    Saved 10 candidates for 愛媛.\n",
            "  Scraping candidates for 高知...\n",
            "    Saved 6 candidates for 高知.\n",
            "  Scraping candidates for 福岡...\n",
            "    Saved 42 candidates for 福岡.\n",
            "  Scraping candidates for 佐賀...\n",
            "    Saved 5 candidates for 佐賀.\n",
            "  Scraping candidates for 長崎...\n",
            "    Saved 10 candidates for 長崎.\n",
            "  Scraping candidates for 熊本...\n",
            "    Saved 14 candidates for 熊本.\n",
            "  Scraping candidates for 大分...\n",
            "    Saved 12 candidates for 大分.\n",
            "  Scraping candidates for 宮崎...\n",
            "    Saved 9 candidates for 宮崎.\n",
            "  Scraping candidates for 鹿児島...\n",
            "    Saved 13 candidates for 鹿児島.\n",
            "  Scraping candidates for 沖縄...\n",
            "    Saved 17 candidates for 沖縄.\n",
            "Skipping non-prefecture entry: #選挙・鳥取\n",
            "Skipping non-prefecture entry: #選挙・北海道\n",
            "Skipping non-prefecture entry: #選挙・茨城\n",
            "Skipping non-prefecture entry: #選挙・茨城\n",
            "Skipping non-prefecture entry: #選挙・富山\n",
            "Skipping non-prefecture entry: #選挙・山形\n",
            "Skipping non-prefecture entry: #選挙・千葉\n",
            "Skipping non-prefecture entry: #選挙・埼玉\n",
            "Skipping non-prefecture entry: #選挙・神奈川\n",
            "Skipping non-prefecture entry: #選挙・東京\n",
            "  Scraping candidates for 北海道...\n",
            "    Saved 38 candidates for 北海道.\n",
            "  Scraping candidates for 青森...\n",
            "    Saved 11 candidates for 青森.\n",
            "  Scraping candidates for 岩手...\n",
            "    Saved 10 candidates for 岩手.\n",
            "  Scraping candidates for 宮城...\n",
            "    Saved 21 candidates for 宮城.\n",
            "  Scraping candidates for 秋田...\n",
            "    Saved 10 candidates for 秋田.\n",
            "  Scraping candidates for 山形...\n",
            "    Saved 10 candidates for 山形.\n",
            "  Scraping candidates for 福島...\n",
            "    Saved 15 candidates for 福島.\n",
            "  Scraping candidates for 茨城...\n",
            "    Saved 23 candidates for 茨城.\n",
            "  Scraping candidates for 栃木...\n",
            "    Saved 20 candidates for 栃木.\n",
            "  Scraping candidates for 群馬...\n",
            "    Saved 17 candidates for 群馬.\n",
            "  Scraping candidates for 埼玉...\n",
            "    Saved 55 candidates for 埼玉.\n",
            "  Scraping candidates for 東京...\n",
            "    Saved 154 candidates for 東京.\n",
            "  Scraping candidates for 千葉...\n",
            "    Saved 52 candidates for 千葉.\n",
            "  Scraping candidates for 神奈川...\n",
            "    Saved 70 candidates for 神奈川.\n",
            "  Scraping candidates for 山梨...\n",
            "    Saved 6 candidates for 山梨.\n",
            "  Scraping candidates for 新潟...\n",
            "    Saved 19 candidates for 新潟.\n",
            "  Scraping candidates for 富山...\n",
            "    Saved 10 candidates for 富山.\n",
            "  Scraping candidates for 石川...\n",
            "    Saved 10 candidates for 石川.\n",
            "  Scraping candidates for 福井...\n",
            "    Saved 6 candidates for 福井.\n",
            "  Scraping candidates for 長野...\n",
            "    Saved 16 candidates for 長野.\n",
            "  Scraping candidates for 岐阜...\n",
            "    Saved 20 candidates for 岐阜.\n",
            "  Scraping candidates for 静岡...\n",
            "    Saved 26 candidates for 静岡.\n",
            "  Scraping candidates for 愛知...\n",
            "    Saved 68 candidates for 愛知.\n",
            "  Scraping candidates for 三重...\n",
            "    Saved 14 candidates for 三重.\n",
            "  Scraping candidates for 滋賀...\n",
            "    Saved 13 candidates for 滋賀.\n",
            "  Scraping candidates for 京都...\n",
            "    Saved 27 candidates for 京都.\n",
            "  Scraping candidates for 大阪...\n",
            "    Saved 84 candidates for 大阪.\n",
            "  Scraping candidates for 兵庫...\n",
            "    Saved 53 candidates for 兵庫.\n",
            "  Scraping candidates for 奈良...\n",
            "    Saved 11 candidates for 奈良.\n",
            "  Scraping candidates for 和歌山...\n",
            "    Saved 9 candidates for 和歌山.\n",
            "  Scraping candidates for 鳥取...\n",
            "    Saved 7 candidates for 鳥取.\n",
            "  Scraping candidates for 島根...\n",
            "    Saved 8 candidates for 島根.\n",
            "  Scraping candidates for 岡山...\n",
            "    Saved 15 candidates for 岡山.\n",
            "  Scraping candidates for 広島...\n",
            "    Saved 25 candidates for 広島.\n",
            "  Scraping candidates for 山口...\n",
            "    Saved 10 candidates for 山口.\n",
            "  Scraping candidates for 徳島...\n",
            "    Saved 8 candidates for 徳島.\n",
            "  Scraping candidates for 香川...\n",
            "    Saved 10 candidates for 香川.\n",
            "  Scraping candidates for 愛媛...\n",
            "    Saved 10 candidates for 愛媛.\n",
            "  Scraping candidates for 高知...\n",
            "    Saved 6 candidates for 高知.\n",
            "  Scraping candidates for 福岡...\n",
            "    Saved 42 candidates for 福岡.\n",
            "  Scraping candidates for 佐賀...\n",
            "    Saved 5 candidates for 佐賀.\n",
            "  Scraping candidates for 長崎...\n",
            "    Saved 10 candidates for 長崎.\n",
            "  Scraping candidates for 熊本...\n",
            "    Saved 14 candidates for 熊本.\n",
            "  Scraping candidates for 大分...\n",
            "    Saved 12 candidates for 大分.\n",
            "  Scraping candidates for 宮崎...\n",
            "    Saved 9 candidates for 宮崎.\n",
            "  Scraping candidates for 鹿児島...\n",
            "    Saved 13 candidates for 鹿児島.\n",
            "  Scraping candidates for 沖縄...\n",
            "    Saved 17 candidates for 沖縄.\n",
            "\n",
            "--- Summary ---\n",
            "Total prefectures processed: 94\n",
            "Total candidate entries saved: 2238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "262307b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf8fb8d-42f8-4256-e46c-af46e5152886"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def clean_invalid_prefecture_folders(base_dir='prefecture_data'):\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(f\"Directory '{base_dir}' does not exist. Nothing to clean.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Checking for and removing invalid prefecture folders in '{base_dir}'...\")\n",
        "    for item in os.listdir(base_dir):\n",
        "        full_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(full_path) and item.startswith('#選挙・'):\n",
        "            print(f\"  Removing folder: {item}\")\n",
        "            try:\n",
        "                shutil.rmtree(full_path)\n",
        "                print(f\"  Successfully removed '{item}'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error removing '{item}': {e}\")\n",
        "        else:\n",
        "            # print(f\"  Keeping folder: {item}\") # Optional: to see which folders are kept\n",
        "            pass\n",
        "    print(\"Cleanup complete.\")\n",
        "\n",
        "# Call the cleanup function\n",
        "clean_invalid_prefecture_folders()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for and removing invalid prefecture folders in 'prefecture_data'...\n",
            "Cleanup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b90cc64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a301f6-00e8-408e-d96d-ca28ba4cefe6"
      },
      "source": [
        "unique_names = set()\n",
        "for prefecture, candidates_list in all_scraped_data.items():\n",
        "    for candidate in candidates_list:\n",
        "        # The name might still contain age or other details, try to clean it.\n",
        "        # Re-using the regex from `get_candidates_for_prefecture` for consistency.\n",
        "        name_full = candidate['candidate_name']\n",
        "        name_match = re.match(r'([\\w\\s\\u3000\\u4e00-\\u9fff]+)\\d+歳', name_full)\n",
        "        cleaned_name = name_match.group(1).strip() if name_match else name_full\n",
        "        unique_names.add(cleaned_name)\n",
        "\n",
        "total_unique_names = len(unique_names)\n",
        "print(f\"ユニークな候補者名の総数: {total_unique_names}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ユニークな候補者名の総数: 1118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6303a34a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5026ec6b-0e4f-4479-db55-88ed445770b7"
      },
      "source": [
        "proportional_district_urls = []\n",
        "\n",
        "for i in range(81, 92):  # Loop from 81 to 91 (inclusive)\n",
        "    district_code = f\"{i:02d}\"  # Format to two digits (e.g., 81, 91)\n",
        "    url = f\"https://www.yomiuri.co.jp/election/shugiin/YC{district_code}XXXXXX000/\"\n",
        "    proportional_district_urls.append(url)\n",
        "\n",
        "print(f\"Generated {len(proportional_district_urls)} proportional district URLs:\")\n",
        "for url in proportional_district_urls:\n",
        "    print(url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 11 proportional district URLs:\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC81XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC82XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC83XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC84XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC85XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC86XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC87XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC88XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC89XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC90XXXXXX000/\n",
            "https://www.yomiuri.co.jp/election/shugiin/YC91XXXXXX000/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "843984a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6e3f0c-6b6d-4ca6-eb8f-7400a5e3575c"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import re # Import regex module\n",
        "\n",
        "def get_candidates_for_proportional_district(proportional_district_url):\n",
        "    try:\n",
        "        response = requests.get(proportional_district_url)\n",
        "        response.raise_for_status()  # Check for HTTP errors\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        candidate_data = []\n",
        "        # Regex to match proportional district code (81-91)\n",
        "        district_code_match = re.search(r'YC(8[1-9]|9[0-1])XXXXXX000', proportional_district_url)\n",
        "        if not district_code_match:\n",
        "            print(f\"Could not extract proportional district code from URL: {proportional_district_url}\")\n",
        "            return []\n",
        "        district_code = district_code_match.group(1)\n",
        "\n",
        "        # Construct the pattern for candidate detail pages within this proportional district\n",
        "        # Example: 'https://www.yomiuri.co.jp/election/shugiin/2026/YC81XXXXXX000/135847/'\n",
        "        candidate_pattern = rf'^https://www.yomiuri.co.jp/election/shugiin/2026/YC{district_code}XXXXXX000/\\d+/$'\n",
        "\n",
        "        all_links = soup.find_all('a', href=True)\n",
        "\n",
        "        for link_tag in all_links:\n",
        "            absolute_link = urljoin(proportional_district_url, link_tag.get('href'))\n",
        "            # Check if the link matches the candidate pattern\n",
        "            if re.match(candidate_pattern, absolute_link):\n",
        "                candidate_name_full = link_tag.get_text(strip=True)\n",
        "                # Attempt to extract just the name before age or other details\n",
        "                name_match = re.match(r'([\\w\\s\\u3000\\u4e00-\\u9fff]+)\\d+歳', candidate_name_full)\n",
        "                candidate_name = name_match.group(1).strip() if name_match else candidate_name_full\n",
        "\n",
        "                if candidate_name: # Ensure a name exists\n",
        "                    candidate_data.append({'candidate_name': candidate_name, 'candidate_url': absolute_link})\n",
        "\n",
        "        # Remove duplicate entries based on candidate_url\n",
        "        unique_candidate_data = []\n",
        "        seen_urls = set()\n",
        "        for item in candidate_data:\n",
        "            if item['candidate_url'] not in seen_urls:\n",
        "                unique_candidate_data.append(item)\n",
        "                seen_urls.add(item['candidate_url'])\n",
        "\n",
        "        return unique_candidate_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for {proportional_district_url}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during parsing {proportional_district_url}: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"Function `get_candidates_for_proportional_district` defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function `get_candidates_for_proportional_district` defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5763c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4559e1eb-0e5e-479f-dce7-cad75a2d0137"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "def clean_invalid_proportional_folders(base_dir='proportional_data'):\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(f\"Directory '{base_dir}' does not exist. Nothing to clean.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Checking for and removing invalid proportional folders in '{base_dir}'...\")\n",
        "    for item in os.listdir(base_dir):\n",
        "        full_path = os.path.join(base_dir, item)\n",
        "        # Check if it's a directory and matches the YCXX pattern\n",
        "        if os.path.isdir(full_path) and re.match(r'^YC\\d+$', item):\n",
        "            print(f\"  Removing folder: {item}\")\n",
        "            try:\n",
        "                shutil.rmtree(full_path)\n",
        "                print(f\"  Successfully removed '{item}'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error removing '{item}': {e}\")\n",
        "    print(\"Cleanup complete.\")\n",
        "\n",
        "# Call the cleanup function\n",
        "clean_invalid_proportional_folders()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'proportional_data' does not exist. Nothing to clean.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12a716f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6956b46-5fcc-4287-9723-872861f089fa"
      },
      "source": [
        "all_proportional_candidates = {}\n",
        "\n",
        "print(f\"\\nScraping candidates from {len(proportional_district_urls)} proportional district pages...\")\n",
        "\n",
        "for url in proportional_district_urls:\n",
        "    # Extract district name (e.g., 'YC81') from the URL for dictionary key\n",
        "    district_name_match = re.search(r'(YC\\d+)XXXXXX000', url)\n",
        "    district_name = district_name_match.group(1) if district_name_match else url\n",
        "\n",
        "    print(f\"  Scraping candidates for {district_name} ({url})...\")\n",
        "    candidates_list = get_candidates_for_proportional_district(url)\n",
        "\n",
        "    if candidates_list:\n",
        "        all_proportional_candidates[district_name] = candidates_list\n",
        "        print(f\"    Found {len(candidates_list)} candidates for {district_name}.\")\n",
        "    else:\n",
        "        print(f\"    No candidates found for {district_name}.\")\n",
        "\n",
        "print(\"\\n--- Proportional District Scrape Summary ---\")\n",
        "total_proportional_candidates = sum(len(v) for v in all_proportional_candidates.values())\n",
        "print(f\"Total proportional districts scraped: {len(all_proportional_candidates)}\")\n",
        "print(f\"Total candidates found in proportional districts: {total_proportional_candidates}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scraping candidates from 11 proportional district pages...\n",
            "  Scraping candidates for YC81 (https://www.yomiuri.co.jp/election/shugiin/YC81XXXXXX000/)...\n",
            "    Found 44 candidates for YC81.\n",
            "  Scraping candidates for YC82 (https://www.yomiuri.co.jp/election/shugiin/YC82XXXXXX000/)...\n",
            "    Found 67 candidates for YC82.\n",
            "  Scraping candidates for YC83 (https://www.yomiuri.co.jp/election/shugiin/YC83XXXXXX000/)...\n",
            "    Found 93 candidates for YC83.\n",
            "  Scraping candidates for YC84 (https://www.yomiuri.co.jp/election/shugiin/YC84XXXXXX000/)...\n",
            "    Found 118 candidates for YC84.\n",
            "  Scraping candidates for YC85 (https://www.yomiuri.co.jp/election/shugiin/YC85XXXXXX000/)...\n",
            "    Found 103 candidates for YC85.\n",
            "  Scraping candidates for YC86 (https://www.yomiuri.co.jp/election/shugiin/YC86XXXXXX000/)...\n",
            "    Found 57 candidates for YC86.\n",
            "  Scraping candidates for YC87 (https://www.yomiuri.co.jp/election/shugiin/YC87XXXXXX000/)...\n",
            "    Found 109 candidates for YC87.\n",
            "  Scraping candidates for YC88 (https://www.yomiuri.co.jp/election/shugiin/YC88XXXXXX000/)...\n",
            "    Found 138 candidates for YC88.\n",
            "  Scraping candidates for YC89 (https://www.yomiuri.co.jp/election/shugiin/YC89XXXXXX000/)...\n",
            "    Found 55 candidates for YC89.\n",
            "  Scraping candidates for YC90 (https://www.yomiuri.co.jp/election/shugiin/YC90XXXXXX000/)...\n",
            "    Found 33 candidates for YC90.\n",
            "  Scraping candidates for YC91 (https://www.yomiuri.co.jp/election/shugiin/YC91XXXXXX000/)...\n",
            "    Found 98 candidates for YC91.\n",
            "\n",
            "--- Proportional District Scrape Summary ---\n",
            "Total proportional districts scraped: 11\n",
            "Total candidates found in proportional districts: 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5489a726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6129230c-57af-48aa-f92f-40765adc574c"
      },
      "source": [
        "proportional_district_name_map = {\n",
        "    'YC81': '北海道ブロック',\n",
        "    'YC82': '東北ブロック',\n",
        "    'YC83': '北関東ブロック',\n",
        "    'YC84': '東京ブロック',\n",
        "    'YC85': '南関東ブロック',\n",
        "    'YC86': '北陸信越ブロック',\n",
        "    'YC87': '東海ブロック',\n",
        "    'YC88': '近畿ブロック',\n",
        "    'YC89': '中国ブロック',\n",
        "    'YC90': '四国ブロック',\n",
        "    'YC91': '九州ブロック',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "比例代表地区名マップが定義されました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c7fa580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdc2a34-d686-40f7-e83b-156cc885018b"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def save_candidates_to_json(district_name, candidates_data, base_dir='proportional_data'):\n",
        "    \"\"\"\n",
        "    Creates a directory for the proportional district and saves candidate data to a JSON file.\n",
        "    \"\"\"\n",
        "    # Use the mapped district name for the directory and file\n",
        "    mapped_district_name = proportional_district_name_map.get(district_name, district_name) # Fallback to original if not found\n",
        "    district_dir = os.path.join(base_dir, mapped_district_name)\n",
        "    os.makedirs(district_dir, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(district_dir, f\"{mapped_district_name}_candidates.json\")\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(candidates_data, f, ensure_ascii=False, indent=4)\n",
        "    return len(candidates_data)\n",
        "\n",
        "\n",
        "# Initialize counters for proportional districts\n",
        "total_proportional_districts_processed = 0\n",
        "total_proportional_candidates_saved = 0\n",
        "\n",
        "# Ensure all_proportional_candidates is available from previous cells\n",
        "if 'all_proportional_candidates' in globals() and all_proportional_candidates:\n",
        "    print(f\"\\nSaving candidates for {len(all_proportional_candidates)} proportional districts...\")\n",
        "    for district_name, candidates_list in all_proportional_candidates.items():\n",
        "        print(f\"  Saving candidates for {district_name}...\")\n",
        "        if candidates_list:\n",
        "            candidates_count = save_candidates_to_json(district_name, candidates_list, base_dir='proportional_data')\n",
        "            total_proportional_districts_processed += 1\n",
        "            total_proportional_candidates_saved += candidates_count\n",
        "            print(f\"    Saved {candidates_count} candidates for {district_name}.\")\n",
        "        else:\n",
        "            print(f\"    No candidates found to save for {district_name}.\")\n",
        "\n",
        "    print(f\"\\n--- Proportional Data Save Summary ---\")\n",
        "    print(f\"Total proportional districts processed: {total_proportional_districts_processed}\")\n",
        "    print(f\"Total proportional candidate entries saved: {total_proportional_candidates_saved}\")\n",
        "else:\n",
        "    print(\"all_proportional_candidates variable not found or is empty. Please ensure previous steps ran successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving candidates for 11 proportional districts...\n",
            "  Saving candidates for YC81...\n",
            "    Saved 44 candidates for YC81.\n",
            "  Saving candidates for YC82...\n",
            "    Saved 67 candidates for YC82.\n",
            "  Saving candidates for YC83...\n",
            "    Saved 93 candidates for YC83.\n",
            "  Saving candidates for YC84...\n",
            "    Saved 118 candidates for YC84.\n",
            "  Saving candidates for YC85...\n",
            "    Saved 103 candidates for YC85.\n",
            "  Saving candidates for YC86...\n",
            "    Saved 57 candidates for YC86.\n",
            "  Saving candidates for YC87...\n",
            "    Saved 109 candidates for YC87.\n",
            "  Saving candidates for YC88...\n",
            "    Saved 138 candidates for YC88.\n",
            "  Saving candidates for YC89...\n",
            "    Saved 55 candidates for YC89.\n",
            "  Saving candidates for YC90...\n",
            "    Saved 33 candidates for YC90.\n",
            "  Saving candidates for YC91...\n",
            "    Saved 98 candidates for YC91.\n",
            "\n",
            "--- Proportional Data Save Summary ---\n",
            "Total proportional districts processed: 11\n",
            "Total proportional candidate entries saved: 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfc9d743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7f9446-7876-419a-b9bc-df5cf0eeaf58"
      },
      "source": [
        "print(f\"\\n--- Final Summary for Proportional Districts ---\")\n",
        "print(f\"Total proportional districts processed: {total_proportional_districts_processed}\")\n",
        "print(f\"Total proportional candidate entries saved: {total_proportional_candidates_saved}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Summary for Proportional Districts ---\n",
            "Total proportional districts processed: 11\n",
            "Total proportional candidate entries saved: 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 設問と回答を収集"
      ],
      "metadata": {
        "id": "x6XOuvHgIGs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y \\\n",
        "  libatk1.0-0 libatk-bridge2.0-0 libatspi2.0-0 \\\n",
        "  libgtk-3-0 libgbm1 libnss3 libnspr4 \\\n",
        "  libcups2 libxkbcommon0 libxshmfence1 \\\n",
        "  libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxdamage1 libxrandr2 \\\n",
        "  libxext6 libxfixes3 \\\n",
        "  libpango-1.0-0 libpangocairo-1.0-0 libcairo2 \\\n",
        "  libdrm2 libdbus-1-3 \\\n",
        "  libasound2\n"
      ],
      "metadata": {
        "id": "Q-n6x-A8TxHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ecb9cef-7406-424e-f702-89b6ab377b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connecting to security.\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [2 InRelease 3,632 B/3,632 B 100\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [3 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.8 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,679 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,640 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,887 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,571 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,288 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,293 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,999 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,605 kB]\n",
            "Fetched 36.7 MB in 3s (11.0 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libasound2 set to manually installed.\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo2 set to manually installed.\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb1 set to manually installed.\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxdamage1 set to manually installed.\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxfixes3 set to manually installed.\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxkbcommon0 set to manually installed.\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "libxrandr2 set to manually installed.\n",
            "libxshmfence1 is already the newest version (1.3-1build4).\n",
            "libxshmfence1 set to manually installed.\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.16).\n",
            "libcups2 set to manually installed.\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdbus-1-3 set to manually installed.\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libdrm2 set to manually installed.\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libgbm1 set to manually installed.\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnspr4 set to manually installed.\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libnss3 set to manually installed.\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpango-1.0-0 set to manually installed.\n",
            "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpangocairo-1.0-0 set to manually installed.\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-6 set to manually installed.\n",
            "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-xcb1 set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core gsettings-desktop-schemas libatk1.0-data libgtk-3-bin\n",
            "  libgtk-3-common librsvg2-common libxtst6 session-migration\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core gsettings-desktop-schemas libatk-bridge2.0-0 libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgtk-3-0 libgtk-3-bin libgtk-3-common\n",
            "  librsvg2-common libxcomposite1 libxtst6 session-migration\n",
            "0 upgraded, 13 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 3,697 kB of archives.\n",
            "After this operation, 12.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-3-common all 3.24.33-1ubuntu2.2 [239 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-3-0 amd64 3.24.33-1ubuntu2.2 [3,053 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-3-bin amd64 3.24.33-1ubuntu2.2 [69.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Fetched 3,697 kB in 1s (3,734 kB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../05-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../06-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../07-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../08-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libgtk-3-common.\n",
            "Preparing to unpack .../09-libgtk-3-common_3.24.33-1ubuntu2.2_all.deb ...\n",
            "Unpacking libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libgtk-3-0:amd64.\n",
            "Preparing to unpack .../10-libgtk-3-0_3.24.33-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libgtk-3-bin.\n",
            "Preparing to unpack .../11-libgtk-3-bin_3.24.33-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../12-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.7) ...\n",
            "Setting up libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Setting up libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade playwright\n",
        "!playwright install chromium\n"
      ],
      "metadata": {
        "id": "t4QcqcAFTGi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be0c9f3-3020-4b11-ea5b-950486b4cbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Chrome for Testing 145.0.7632.6 (playwright chromium v1208)\u001b[2m from https://cdn.playwright.dev/chrome-for-testing-public/145.0.7632.6/linux64/chrome-linux64.zip\u001b[22m\n",
            "(node:1668) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n",
            "(Use `node --trace-deprecation ...` to show where the warning was created)\n",
            "\u001b[1G167.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G167.3 MiB [] 0% 26.7s\u001b[0K\u001b[1G167.3 MiB [] 0% 14.4s\u001b[0K\u001b[1G167.3 MiB [] 0% 13.3s\u001b[0K\u001b[1G167.3 MiB [] 0% 8.8s\u001b[0K\u001b[1G167.3 MiB [] 1% 6.1s\u001b[0K\u001b[1G167.3 MiB [] 1% 5.1s\u001b[0K\u001b[1G167.3 MiB [] 3% 3.8s\u001b[0K\u001b[1G167.3 MiB [] 3% 3.5s\u001b[0K\u001b[1G167.3 MiB [] 4% 3.4s\u001b[0K\u001b[1G167.3 MiB [] 5% 2.9s\u001b[0K\u001b[1G167.3 MiB [] 6% 2.6s\u001b[0K\u001b[1G167.3 MiB [] 7% 2.5s\u001b[0K\u001b[1G167.3 MiB [] 8% 2.3s\u001b[0K\u001b[1G167.3 MiB [] 9% 2.2s\u001b[0K\u001b[1G167.3 MiB [] 10% 2.1s\u001b[0K\u001b[1G167.3 MiB [] 12% 2.0s\u001b[0K\u001b[1G167.3 MiB [] 13% 1.9s\u001b[0K\u001b[1G167.3 MiB [] 14% 1.8s\u001b[0K\u001b[1G167.3 MiB [] 15% 1.8s\u001b[0K\u001b[1G167.3 MiB [] 16% 1.8s\u001b[0K\u001b[1G167.3 MiB [] 17% 1.7s\u001b[0K\u001b[1G167.3 MiB [] 18% 1.6s\u001b[0K\u001b[1G167.3 MiB [] 19% 1.6s\u001b[0K\u001b[1G167.3 MiB [] 20% 1.6s\u001b[0K\u001b[1G167.3 MiB [] 21% 1.5s\u001b[0K\u001b[1G167.3 MiB [] 22% 1.5s\u001b[0K\u001b[1G167.3 MiB [] 24% 1.4s\u001b[0K\u001b[1G167.3 MiB [] 25% 1.4s\u001b[0K\u001b[1G167.3 MiB [] 26% 1.3s\u001b[0K\u001b[1G167.3 MiB [] 28% 1.3s\u001b[0K\u001b[1G167.3 MiB [] 29% 1.2s\u001b[0K\u001b[1G167.3 MiB [] 31% 1.2s\u001b[0K\u001b[1G167.3 MiB [] 33% 1.1s\u001b[0K\u001b[1G167.3 MiB [] 34% 1.1s\u001b[0K\u001b[1G167.3 MiB [] 36% 1.1s\u001b[0K\u001b[1G167.3 MiB [] 37% 1.0s\u001b[0K\u001b[1G167.3 MiB [] 39% 1.0s\u001b[0K\u001b[1G167.3 MiB [] 40% 1.0s\u001b[0K\u001b[1G167.3 MiB [] 41% 0.9s\u001b[0K\u001b[1G167.3 MiB [] 43% 0.9s\u001b[0K\u001b[1G167.3 MiB [] 44% 0.9s\u001b[0K\u001b[1G167.3 MiB [] 45% 0.9s\u001b[0K\u001b[1G167.3 MiB [] 46% 0.9s\u001b[0K\u001b[1G167.3 MiB [] 46% 0.8s\u001b[0K\u001b[1G167.3 MiB [] 47% 0.8s\u001b[0K\u001b[1G167.3 MiB [] 49% 0.8s\u001b[0K\u001b[1G167.3 MiB [] 50% 0.8s\u001b[0K\u001b[1G167.3 MiB [] 52% 0.7s\u001b[0K\u001b[1G167.3 MiB [] 53% 0.7s\u001b[0K\u001b[1G167.3 MiB [] 54% 0.7s\u001b[0K\u001b[1G167.3 MiB [] 56% 0.7s\u001b[0K\u001b[1G167.3 MiB [] 57% 0.6s\u001b[0K\u001b[1G167.3 MiB [] 59% 0.6s\u001b[0K\u001b[1G167.3 MiB [] 60% 0.6s\u001b[0K\u001b[1G167.3 MiB [] 62% 0.6s\u001b[0K\u001b[1G167.3 MiB [] 63% 0.5s\u001b[0K\u001b[1G167.3 MiB [] 65% 0.5s\u001b[0K\u001b[1G167.3 MiB [] 66% 0.5s\u001b[0K\u001b[1G167.3 MiB [] 67% 0.5s\u001b[0K\u001b[1G167.3 MiB [] 68% 0.5s\u001b[0K\u001b[1G167.3 MiB [] 69% 0.5s\u001b[0K\u001b[1G167.3 MiB [] 70% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 71% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 72% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 73% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 74% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 75% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 76% 0.4s\u001b[0K\u001b[1G167.3 MiB [] 77% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 79% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 80% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 81% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 82% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 83% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 84% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 85% 0.3s\u001b[0K\u001b[1G167.3 MiB [] 86% 0.2s\u001b[0K\u001b[1G167.3 MiB [] 88% 0.2s\u001b[0K\u001b[1G167.3 MiB [] 89% 0.2s\u001b[0K\u001b[1G167.3 MiB [] 91% 0.2s\u001b[0K\u001b[1G167.3 MiB [] 92% 0.1s\u001b[0K\u001b[1G167.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G167.3 MiB [] 94% 0.1s\u001b[0K\u001b[1G167.3 MiB [] 96% 0.1s\u001b[0K\u001b[1G167.3 MiB [] 97% 0.0s\u001b[0K\u001b[1G167.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G167.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Chrome for Testing 145.0.7632.6 (playwright chromium v1208) downloaded to /root/.cache/ms-playwright/chromium-1208\n",
            "Downloading FFmpeg (playwright ffmpeg v1011)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "(node:1703) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n",
            "(Use `node --trace-deprecation ...` to show where the warning was created)\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 28% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 90% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFmpeg (playwright ffmpeg v1011) downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Downloading Chrome Headless Shell 145.0.7632.6 (playwright chromium-headless-shell v1208)\u001b[2m from https://cdn.playwright.dev/chrome-for-testing-public/145.0.7632.6/linux64/chrome-headless-shell-linux64.zip\u001b[22m\n",
            "(node:1718) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n",
            "(Use `node --trace-deprecation ...` to show where the warning was created)\n",
            "\u001b[1G110.9 MiB [] 0% 0.0s\u001b[0K\u001b[1G110.9 MiB [] 0% 32.5s\u001b[0K\u001b[1G110.9 MiB [] 0% 10.2s\u001b[0K\u001b[1G110.9 MiB [] 0% 6.0s\u001b[0K\u001b[1G110.9 MiB [] 2% 2.7s\u001b[0K\u001b[1G110.9 MiB [] 4% 2.0s\u001b[0K\u001b[1G110.9 MiB [] 5% 1.6s\u001b[0K\u001b[1G110.9 MiB [] 6% 1.8s\u001b[0K\u001b[1G110.9 MiB [] 7% 1.6s\u001b[0K\u001b[1G110.9 MiB [] 9% 1.4s\u001b[0K\u001b[1G110.9 MiB [] 11% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 12% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 13% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 13% 1.4s\u001b[0K\u001b[1G110.9 MiB [] 13% 1.5s\u001b[0K\u001b[1G110.9 MiB [] 14% 1.5s\u001b[0K\u001b[1G110.9 MiB [] 15% 1.5s\u001b[0K\u001b[1G110.9 MiB [] 16% 1.4s\u001b[0K\u001b[1G110.9 MiB [] 17% 1.4s\u001b[0K\u001b[1G110.9 MiB [] 18% 1.4s\u001b[0K\u001b[1G110.9 MiB [] 19% 1.4s\u001b[0K\u001b[1G110.9 MiB [] 20% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 21% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 22% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 23% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 24% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 25% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 26% 1.3s\u001b[0K\u001b[1G110.9 MiB [] 27% 1.2s\u001b[0K\u001b[1G110.9 MiB [] 28% 1.2s\u001b[0K\u001b[1G110.9 MiB [] 29% 1.2s\u001b[0K\u001b[1G110.9 MiB [] 30% 1.2s\u001b[0K\u001b[1G110.9 MiB [] 31% 1.1s\u001b[0K\u001b[1G110.9 MiB [] 32% 1.1s\u001b[0K\u001b[1G110.9 MiB [] 34% 1.1s\u001b[0K\u001b[1G110.9 MiB [] 35% 1.0s\u001b[0K\u001b[1G110.9 MiB [] 37% 1.0s\u001b[0K\u001b[1G110.9 MiB [] 38% 1.0s\u001b[0K\u001b[1G110.9 MiB [] 40% 0.9s\u001b[0K\u001b[1G110.9 MiB [] 42% 0.9s\u001b[0K\u001b[1G110.9 MiB [] 43% 0.9s\u001b[0K\u001b[1G110.9 MiB [] 44% 0.8s\u001b[0K\u001b[1G110.9 MiB [] 46% 0.8s\u001b[0K\u001b[1G110.9 MiB [] 47% 0.8s\u001b[0K\u001b[1G110.9 MiB [] 48% 0.8s\u001b[0K\u001b[1G110.9 MiB [] 50% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 51% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 52% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 53% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 54% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 55% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 56% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 57% 0.7s\u001b[0K\u001b[1G110.9 MiB [] 58% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 59% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 60% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 61% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 62% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 63% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 64% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 65% 0.6s\u001b[0K\u001b[1G110.9 MiB [] 66% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 67% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 68% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 69% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 70% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 71% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 72% 0.5s\u001b[0K\u001b[1G110.9 MiB [] 73% 0.4s\u001b[0K\u001b[1G110.9 MiB [] 74% 0.4s\u001b[0K\u001b[1G110.9 MiB [] 75% 0.4s\u001b[0K\u001b[1G110.9 MiB [] 76% 0.4s\u001b[0K\u001b[1G110.9 MiB [] 77% 0.4s\u001b[0K\u001b[1G110.9 MiB [] 78% 0.4s\u001b[0K\u001b[1G110.9 MiB [] 79% 0.3s\u001b[0K\u001b[1G110.9 MiB [] 80% 0.3s\u001b[0K\u001b[1G110.9 MiB [] 81% 0.3s\u001b[0K\u001b[1G110.9 MiB [] 82% 0.3s\u001b[0K\u001b[1G110.9 MiB [] 83% 0.3s\u001b[0K\u001b[1G110.9 MiB [] 84% 0.3s\u001b[0K\u001b[1G110.9 MiB [] 85% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 86% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 87% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 88% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 89% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 90% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 91% 0.2s\u001b[0K\u001b[1G110.9 MiB [] 92% 0.1s\u001b[0K\u001b[1G110.9 MiB [] 93% 0.1s\u001b[0K\u001b[1G110.9 MiB [] 94% 0.1s\u001b[0K\u001b[1G110.9 MiB [] 95% 0.1s\u001b[0K\u001b[1G110.9 MiB [] 96% 0.1s\u001b[0K\u001b[1G110.9 MiB [] 97% 0.0s\u001b[0K\u001b[1G110.9 MiB [] 98% 0.0s\u001b[0K\u001b[1G110.9 MiB [] 99% 0.0s\u001b[0K\u001b[1G110.9 MiB [] 100% 0.0s\u001b[0K\n",
            "Chrome Headless Shell 145.0.7632.6 (playwright chromium-headless-shell v1208) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, re, hashlib, random\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "# =========================================================\n",
        "# 設定（直列・安定版）\n",
        "# =========================================================\n",
        "LIMIT_PER_UNIT = None   # 各県/各ブロックで先頭N件だけ。Noneなら全件\n",
        "DATA_ROOT_PREF = \"prefecture_data\"\n",
        "DATA_ROOT_PROP = \"proportional_data\"\n",
        "\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/yomiuri_enquete_2026\"\n",
        "OUT_DIR_PREF = os.path.join(DRIVE_BASE_DIR, \"prefecture\")\n",
        "OUT_DIR_PROP = os.path.join(DRIVE_BASE_DIR, \"proportional\")\n",
        "OUT_DIR_ALL  = os.path.join(DRIVE_BASE_DIR, \"all\")\n",
        "\n",
        "# URL単位キャッシュ（再起動対策）\n",
        "CACHE_DIR = os.path.join(DRIVE_BASE_DIR, \"cache_candidates\")  # 1候補者=1ファイル\n",
        "\n",
        "# 最後に URL 重複を消す（pref/proportional両方に出る想定）\n",
        "DROP_DUPLICATE_BY_URL = True\n",
        "\n",
        "# ブロック回避（直列でも少し散らす）\n",
        "JITTER_SEC = 1.2\n",
        "\n",
        "# リトライ\n",
        "RETRIES = 1\n",
        "BASE_BACKOFF_SEC = 1.0\n",
        "\n",
        "# タイムアウト\n",
        "GOTO_TIMEOUT_MS = 120000\n",
        "WAIT_Q_WRAPPER_TIMEOUT_MS = 5000\n",
        "WAIT_ANSWER_EVIDENCE_MAX_MS = 1500  # 回答が入るまで最大待つ時間\n",
        "WAIT_ANSWER_POLL_MS = 500\n",
        "\n",
        "# 回答が1つも取れない場合は fail 扱いにする（空OKキャッシュを防ぐ）\n",
        "TREAT_EMPTY_ANSWERS_AS_FAIL = False\n",
        "\n",
        "# ★Q24は固定で 1..11 を必ず列として救う（未回答は空欄）\n",
        "FORCE_Q24_SUBKEYS = 11\n",
        "\n",
        "# =========================================================\n",
        "\n",
        "for d in [OUT_DIR_PREF, OUT_DIR_PROP, OUT_DIR_ALL, CACHE_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# キャッシュ\n",
        "# ---------------------------------------------------------\n",
        "def url_to_cache_path(url: str) -> str:\n",
        "    h = hashlib.sha1(url.encode(\"utf-8\")).hexdigest()\n",
        "    return os.path.join(CACHE_DIR, f\"{h}.json\")\n",
        "\n",
        "def load_cached_row(url: str):\n",
        "    path = url_to_cache_path(url)\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def save_cached_row(url: str, row: dict):\n",
        "    path = url_to_cache_path(url)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(row, f, ensure_ascii=False)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 文字処理\n",
        "# ---------------------------------------------------------\n",
        "def clean_text(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
        "\n",
        "def first_int(text: str) -> str:\n",
        "    m = re.search(r\"\\d+\", text or \"\")\n",
        "    return m.group(0) if m else \"\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# プロフィール抽出\n",
        "# ---------------------------------------------------------\n",
        "def extract_party_dom_first(soup: BeautifulSoup) -> str:\n",
        "    for dt in soup.select(\"dt\"):\n",
        "        if dt.get_text(strip=True) in (\"党派\", \"政党\"):\n",
        "            dd = dt.find_next_sibling(\"dd\")\n",
        "            if dd:\n",
        "                v = clean_text(dd.get_text(\" \", strip=True))\n",
        "                if v:\n",
        "                    return v\n",
        "\n",
        "    for th in soup.select(\"th\"):\n",
        "        if th.get_text(strip=True) in (\"党派\", \"政党\"):\n",
        "            td = th.find_next_sibling(\"td\")\n",
        "            if td:\n",
        "                v = clean_text(td.get_text(\" \", strip=True))\n",
        "                if v:\n",
        "                    return v\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def extract_profile(soup: BeautifulSoup) -> dict:\n",
        "    text_all = soup.get_text(\"\\n\", strip=True)\n",
        "\n",
        "    name = \"\"\n",
        "    h1 = soup.select_one(\"h1\")\n",
        "    if h1:\n",
        "        name = clean_text(h1.get_text(\" \", strip=True))\n",
        "\n",
        "    age = \"\"\n",
        "    m_age = re.search(r\"年齢\\s*([0-9]{1,3})\\s*歳\", text_all)\n",
        "    if m_age:\n",
        "        age = m_age.group(1)\n",
        "\n",
        "    party = extract_party_dom_first(soup)\n",
        "    if not party:\n",
        "        m_party = re.search(r\"(党派|政党)\\s*([^\\n]+)\", text_all)\n",
        "        if m_party:\n",
        "            party = clean_text(m_party.group(2))\n",
        "\n",
        "    if party:\n",
        "        party = re.split(r\"\\s+新旧|\\s+新|\\s+前|\\s+当選|\\s+経歴\", party)[0].strip()\n",
        "\n",
        "    return {\"氏名\": name, \"年齢\": age, \"政党\": party}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 回答抽出（設問番号→回答番号）\n",
        "# ---------------------------------------------------------\n",
        "def parse_answers(soup: BeautifulSoup) -> dict:\n",
        "    out = {}\n",
        "    for wrap in soup.select(\"div.candidate_profile_enquete_wrapper[id^='question']\"):\n",
        "        m = re.search(r\"question(\\d+)\", wrap.get(\"id\", \"\"))\n",
        "        if not m:\n",
        "            continue\n",
        "        qnum = m.group(1)\n",
        "\n",
        "        # Q1（順位）\n",
        "        q01_ranks = wrap.select(\"li.candidate_profile_enquete_q01_answer_rank\")\n",
        "        if q01_ranks:\n",
        "            rank_no = 1\n",
        "            for li in q01_ranks:\n",
        "                span = li.select_one(\"div.candidate_profile_enquete_q01_answer_text span\")\n",
        "                out[f\"Q{qnum}-{rank_no}\"] = first_int(span.get_text(strip=True)) if span else \"\"\n",
        "                rank_no += 1\n",
        "            continue\n",
        "\n",
        "        # Q9（a-f）→ 連番\n",
        "        themes = wrap.select(\"li.candidate_profile_enquete_q09_answer_theme\")\n",
        "        ans_spans = wrap.select(\"li.candidate_profile_enquete_q09_answer_text span\")\n",
        "        if themes and ans_spans:\n",
        "            idx = 1\n",
        "            for sp in ans_spans:\n",
        "                out[f\"Q{qnum}-{idx}\"] = first_int(sp.get_text(strip=True))\n",
        "                idx += 1\n",
        "            continue\n",
        "\n",
        "        # 複数選択（Q24など）\n",
        "        multi_spans = wrap.select(f\"#answer{qnum} .candidate_profile_enquete_answer_text span\")\n",
        "        if len(multi_spans) >= 2:\n",
        "            i = 1\n",
        "            for sp in multi_spans:\n",
        "                out[f\"Q{qnum}-{i}\"] = first_int(sp.get_text(strip=True))\n",
        "                i += 1\n",
        "            continue\n",
        "\n",
        "        # Q25：active（0-10）\n",
        "        q25_graphs = wrap.select(\"div.candiate_profile_enquete_q25_answer_1axis_graph\")\n",
        "        q25_names = wrap.select(\"div.candiate_profile_enquete_q25_name\")\n",
        "        if q25_graphs and q25_names:\n",
        "            idx = 1\n",
        "            for graph in q25_graphs:\n",
        "                active = graph.select_one(\".scales .scale.active\")\n",
        "                ans_num = \"\"\n",
        "                if active:\n",
        "                    cls = \" \".join(active.get(\"class\", []))\n",
        "                    mscale = re.search(r\"scale(\\d+)\", cls)\n",
        "                    if mscale:\n",
        "                        ans_num = mscale.group(1)\n",
        "                out[f\"Q{qnum}-{idx}\"] = ans_num\n",
        "                idx += 1\n",
        "            continue\n",
        "\n",
        "        # 通常 単一\n",
        "        span = wrap.select_one(\"p.candidate_profile_enquete_answer_text span\")\n",
        "        out[f\"Q{qnum}\"] = first_int(span.get_text(strip=True)) if span else \"\"\n",
        "\n",
        "    return out\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Playwright：回答が「入った」ことを待つ（重要）\n",
        "# ---------------------------------------------------------\n",
        "ANSWER_EVIDENCE_SELECTORS = [\n",
        "    \"p.candidate_profile_enquete_answer_text span\",           # 通常回答\n",
        "    \"li.candidate_profile_enquete_q01_answer_rank span\",      # Q1順位\n",
        "    \"li.candidate_profile_enquete_q09_answer_text span\",      # Q9(a-f)\n",
        "    \"div.candidate_profile_enquete_answer_text span\",         # 複数選択系\n",
        "    \"div.candiate_profile_enquete_q25_answer_1axis_graph .scale.active\",  # Q25\n",
        "]\n",
        "\n",
        "from playwright.async_api import TimeoutError as PlaywrightTimeoutError\n",
        "\n",
        "async def wait_answers_ready(page) -> bool:\n",
        "    \"\"\"\n",
        "    質問ブロック(wrapper)が出るのを待つが、\n",
        "    timeoutしても例外にせず False を返す（＝未回答/構造違い扱い）\n",
        "    \"\"\"\n",
        "    try:\n",
        "        await page.wait_for_selector(\n",
        "            \"div.candidate_profile_enquete_wrapper[id^='question']\",\n",
        "            timeout=WAIT_Q_WRAPPER_TIMEOUT_MS\n",
        "        )\n",
        "    except PlaywrightTimeoutError:\n",
        "        return False\n",
        "\n",
        "    loops = max(1, WAIT_ANSWER_EVIDENCE_MAX_MS // WAIT_ANSWER_POLL_MS)\n",
        "    for _ in range(int(loops)):\n",
        "        for sel in ANSWER_EVIDENCE_SELECTORS:\n",
        "            try:\n",
        "                if await page.locator(sel).count() > 0:\n",
        "                    return True\n",
        "            except:\n",
        "                pass\n",
        "        await page.wait_for_timeout(WAIT_ANSWER_POLL_MS)\n",
        "\n",
        "    return False\n",
        "\n",
        "async def fetch_candidate_row(browser, url: str) -> dict:\n",
        "    page = await browser.new_page()\n",
        "    try:\n",
        "        await page.goto(url, wait_until=\"domcontentloaded\", timeout=GOTO_TIMEOUT_MS)\n",
        "        await wait_answers_ready(page)\n",
        "        html = await page.content()\n",
        "    finally:\n",
        "        await page.close()\n",
        "\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    row = {}\n",
        "    row.update(extract_profile(soup))\n",
        "\n",
        "    answers = parse_answers(soup)\n",
        "    row.update(answers)\n",
        "    row[\"URL\"] = url\n",
        "\n",
        "    if TREAT_EMPTY_ANSWERS_AS_FAIL and len(answers) == 0:\n",
        "        raise RuntimeError(\"no answers extracted (possibly JS not ready / blocked)\")\n",
        "\n",
        "    return row\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# DF生成（直列＋キャッシュ＋進捗表示）\n",
        "# ---------------------------------------------------------\n",
        "def q_sort_key(k: str):\n",
        "    m = re.match(r\"Q(\\d+)(?:-(\\d+))?$\", k)\n",
        "    if not m:\n",
        "        return (10**9, 10**9, k)\n",
        "    qn = int(m.group(1))\n",
        "    sub = int(m.group(2)) if m.group(2) else 0\n",
        "    return (qn, sub, k)\n",
        "\n",
        "async def page_sleep(browser, sec: float):\n",
        "    if sec and sec > 0:\n",
        "        import asyncio\n",
        "        await asyncio.sleep(sec)\n",
        "\n",
        "async def build_df(URLS, group_label: str = \"\"):\n",
        "    total = len(URLS)\n",
        "    rows = []\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(\n",
        "            headless=True,\n",
        "            args=[\"--no-sandbox\", \"--disable-dev-shm-usage\"]\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            for i, url in enumerate(URLS, start=1):\n",
        "                await page_sleep(browser, random.uniform(0, JITTER_SEC))\n",
        "\n",
        "                cached = load_cached_row(url)\n",
        "                if cached and cached.get(\"_status\") == \"ok\":\n",
        "                    cached[\"グループ\"] = group_label\n",
        "                    rows.append(cached)\n",
        "                    print(f\"[{group_label}] [{i}/{total}] SKIP(cached): {cached.get('氏名','')}\", flush=True)\n",
        "                    continue\n",
        "\n",
        "                last_err = None\n",
        "                for attempt in range(1, RETRIES + 1):\n",
        "                    try:\n",
        "                        row = await fetch_candidate_row(browser, url)\n",
        "                        row[\"グループ\"] = group_label\n",
        "                        row[\"_status\"] = \"ok\"\n",
        "                        save_cached_row(url, row)\n",
        "                        rows.append(row)\n",
        "                        print(f\"[{group_label}] [{i}/{total}] OK: {row.get('氏名','')}\", flush=True)\n",
        "                        break\n",
        "                    except Exception as e:\n",
        "                        last_err = e\n",
        "                        backoff = BASE_BACKOFF_SEC * (2 ** (attempt - 1)) + random.uniform(0, JITTER_SEC)\n",
        "                        print(\n",
        "                            f\"[{group_label}] [{i}/{total}] RETRY {attempt}/{RETRIES}: {type(e).__name__} sleep {backoff:.1f}s\",\n",
        "                            flush=True\n",
        "                        )\n",
        "                        await page_sleep(browser, backoff)\n",
        "\n",
        "                else:\n",
        "                    fail_row = {\"URL\": url, \"グループ\": group_label, \"_status\": \"fail\", \"_error\": str(last_err)}\n",
        "                    save_cached_row(url, fail_row)\n",
        "                    rows.append(fail_row)\n",
        "                    print(f\"[{group_label}] [{i}/{total}] FAIL: {url}\", flush=True)\n",
        "\n",
        "        finally:\n",
        "            await browser.close()\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Q24固定列（未回答でも列だけ救う）\n",
        "    for i in range(1, FORCE_Q24_SUBKEYS + 1):\n",
        "        col = f\"Q24-{i}\"\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"\"\n",
        "    df = df.drop(columns=[\"Q24\"], errors=\"ignore\")\n",
        "\n",
        "    all_cols = set(df.columns)\n",
        "    base_cols = [c for c in [\"グループ\", \"氏名\", \"年齢\", \"政党\"] if c in all_cols]\n",
        "    q_cols = sorted([c for c in all_cols if re.match(r\"^Q\\d+(-\\d+)?$\", c)], key=q_sort_key)\n",
        "    other_cols = [c for c in [\"URL\", \"_status\", \"_error\"] if c in all_cols]\n",
        "    df = df.reindex(columns=base_cols + q_cols + other_cols)\n",
        "\n",
        "    df = df.drop(columns=[\"Q1\"], errors=\"ignore\")\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# JSON走査\n",
        "# ---------------------------------------------------------\n",
        "def collect_json_files(root_dir: str):\n",
        "    json_files = []\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for fn in filenames:\n",
        "            if fn.endswith(\".json\"):\n",
        "                json_files.append(os.path.join(dirpath, fn))\n",
        "    return sorted(json_files)\n",
        "\n",
        "def load_urls_from_json(json_path: str):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    urls = [item.get(\"candidate_url\") for item in data if item.get(\"candidate_url\")]\n",
        "    if LIMIT_PER_UNIT is not None:\n",
        "        urls = urls[:LIMIT_PER_UNIT]\n",
        "    return urls\n",
        "\n",
        "def safe_unit_name(json_path: str):\n",
        "    return os.path.basename(os.path.dirname(json_path))\n",
        "\n",
        "def save_df_csv(df: pd.DataFrame, out_path: str):\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "    df.to_csv(out_path, index=False)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 政党「多い順」ソート（party csv）\n",
        "# ---------------------------------------------------------\n",
        "def sort_by_party_frequency(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty or \"政党\" not in df.columns:\n",
        "        return df.reset_index(drop=True)\n",
        "\n",
        "    tmp = df.copy()\n",
        "    tmp[\"政党\"] = tmp[\"政党\"].fillna(\"\").astype(str)\n",
        "    tmp[\"氏名\"] = tmp.get(\"氏名\", \"\").fillna(\"\").astype(str)\n",
        "\n",
        "    counts = tmp[\"政党\"].value_counts()\n",
        "    tmp[\"_party_count\"] = tmp[\"政党\"].map(counts).fillna(0).astype(int)\n",
        "    tmp[\"_is_empty_party\"] = (tmp[\"政党\"] == \"\").astype(int)\n",
        "\n",
        "    tmp = tmp.sort_values(\n",
        "        by=[\"_is_empty_party\", \"_party_count\", \"政党\", \"氏名\"],\n",
        "        ascending=[True, False, True, True],\n",
        "        kind=\"stable\"\n",
        "    ).drop(columns=[\"_party_count\", \"_is_empty_party\"], errors=\"ignore\")\n",
        "\n",
        "    return tmp.reset_index(drop=True)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ★追加：ユニット全URLがキャッシュokか判定\n",
        "# ---------------------------------------------------------\n",
        "def unit_all_cached_ok(urls) -> bool:\n",
        "    if not urls:\n",
        "        return False\n",
        "    for url in urls:\n",
        "        cached = load_cached_row(url)\n",
        "        if not cached or cached.get(\"_status\") != \"ok\":\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ★追加：ユニットCSVが読めるか（安全策）\n",
        "# ---------------------------------------------------------\n",
        "def try_read_unit_csv(path: str):\n",
        "    try:\n",
        "        if os.path.exists(path):\n",
        "            return pd.read_csv(path)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# メイン：単位CSV → 全体CSV → party版CSV\n",
        "# ---------------------------------------------------------\n",
        "async def run_all():\n",
        "    # --- prefecture ---\n",
        "    pref_dfs = []\n",
        "    pref_jsons = collect_json_files(DATA_ROOT_PREF)\n",
        "    print(f\"prefecture json files: {len(pref_jsons)}\")\n",
        "\n",
        "    for jp in pref_jsons:\n",
        "        unit = safe_unit_name(jp)\n",
        "        urls = load_urls_from_json(jp)\n",
        "        if not urls:\n",
        "            print(f\"[pref:{unit}] skip (no urls)\")\n",
        "            continue\n",
        "\n",
        "        unit_csv_path = os.path.join(OUT_DIR_PREF, f\"{unit}.csv\")\n",
        "\n",
        "        # ★安全策：全URLがキャッシュokならPlaywright起動せず、CSVがあればそれを読んで集計に入れる\n",
        "        if unit_all_cached_ok(urls):\n",
        "            df_cached = try_read_unit_csv(unit_csv_path)\n",
        "            if df_cached is not None and not df_cached.empty:\n",
        "                pref_dfs.append(df_cached)\n",
        "                print(f\"[pref:{unit}] SKIP (all cached ok, use CSV): {len(urls)} urls\", flush=True)\n",
        "                continue\n",
        "            # CSVが無い/壊れてるなら作り直す（Playwrightは起動する）\n",
        "            print(f\"[pref:{unit}] all cached ok but CSV missing/broken -> rebuild CSV\", flush=True)\n",
        "\n",
        "        df_unit = await build_df(urls, group_label=f\"pref:{unit}\")\n",
        "        save_df_csv(df_unit, unit_csv_path)\n",
        "        pref_dfs.append(df_unit)\n",
        "\n",
        "    df_pref_all = pd.concat(pref_dfs, ignore_index=True) if pref_dfs else pd.DataFrame()\n",
        "    if not df_pref_all.empty:\n",
        "        save_df_csv(df_pref_all, os.path.join(OUT_DIR_PREF, \"_prefecture_all.csv\"))\n",
        "        save_df_csv(sort_by_party_frequency(df_pref_all), os.path.join(OUT_DIR_PREF, \"_prefecture_all_party.csv\"))\n",
        "\n",
        "    # --- proportional ---\n",
        "    prop_dfs = []\n",
        "    prop_jsons = collect_json_files(DATA_ROOT_PROP)\n",
        "    print(f\"proportional json files: {len(prop_jsons)}\")\n",
        "\n",
        "    for jp in prop_jsons:\n",
        "        unit = safe_unit_name(jp)\n",
        "        urls = load_urls_from_json(jp)\n",
        "        if not urls:\n",
        "            print(f\"[prop:{unit}] skip (no urls)\")\n",
        "            continue\n",
        "\n",
        "        unit_csv_path = os.path.join(OUT_DIR_PROP, f\"{unit}.csv\")\n",
        "\n",
        "        # ★安全策：全URLがキャッシュokならPlaywright起動せず、CSVがあればそれを読んで集計に入れる\n",
        "        if unit_all_cached_ok(urls):\n",
        "            df_cached = try_read_unit_csv(unit_csv_path)\n",
        "            if df_cached is not None and not df_cached.empty:\n",
        "                prop_dfs.append(df_cached)\n",
        "                print(f\"[prop:{unit}] SKIP (all cached ok, use CSV): {len(urls)} urls\", flush=True)\n",
        "                continue\n",
        "            print(f\"[prop:{unit}] all cached ok but CSV missing/broken -> rebuild CSV\", flush=True)\n",
        "\n",
        "        df_unit = await build_df(urls, group_label=f\"prop:{unit}\")\n",
        "        save_df_csv(df_unit, unit_csv_path)\n",
        "        prop_dfs.append(df_unit)\n",
        "\n",
        "    df_prop_all = pd.concat(prop_dfs, ignore_index=True) if prop_dfs else pd.DataFrame()\n",
        "    if not df_prop_all.empty:\n",
        "        save_df_csv(df_prop_all, os.path.join(OUT_DIR_PROP, \"_proportional_all.csv\"))\n",
        "        save_df_csv(sort_by_party_frequency(df_prop_all), os.path.join(OUT_DIR_PROP, \"_proportional_all_party.csv\"))\n",
        "\n",
        "    # --- 全候補者（pref + prop） ---\n",
        "    frames = [df for df in [df_pref_all, df_prop_all] if not df.empty]\n",
        "    df_all = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
        "\n",
        "    if not df_all.empty and DROP_DUPLICATE_BY_URL and \"URL\" in df_all.columns:\n",
        "        df_all = df_all.drop_duplicates(subset=[\"URL\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "    if not df_all.empty:\n",
        "        save_df_csv(df_all, os.path.join(OUT_DIR_ALL, \"_all_candidates.csv\"))\n",
        "        save_df_csv(sort_by_party_frequency(df_all), os.path.join(OUT_DIR_ALL, \"_all_candidates_party.csv\"))\n",
        "\n",
        "    return df_pref_all, df_prop_all, df_all\n",
        "\n",
        "# 実行（別セルで）\n",
        "# df_pref_all, df_prop_all, df_all = await run_all()\n"
      ],
      "metadata": {
        "id": "HrQp_RdytE07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "任意：driveのキャッシュをリセットするため"
      ],
      "metadata": {
        "id": "SeWy_RlX6zQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, json, os\n",
        "\"\"\"\n",
        "n_del = 0\n",
        "for path in glob.glob(\"/content/drive/MyDrive/yomiuri_enquete_2026/cache_candidates/*.json\"):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        d = json.load(f)\n",
        "    has_q = any(k.startswith(\"Q\") for k in d.keys())\n",
        "    if d.get(\"_status\") == \"ok\" and (not has_q):\n",
        "        os.remove(path)\n",
        "        n_del += 1\n",
        "\n",
        "print(\"deleted:\", n_del)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "noIdAnFSgcPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pref_all, df_prop_all, df_all = await run_all()"
      ],
      "metadata": {
        "id": "35K8IN0a0gpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c49880-3d15-4da0-e169-f907e8e0dca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prefecture json files: 47\n",
            "[pref:三重] SKIP (all cached ok, use CSV): 14 urls\n",
            "[pref:京都] SKIP (all cached ok, use CSV): 27 urls\n",
            "[pref:佐賀] SKIP (all cached ok, use CSV): 5 urls\n",
            "[pref:兵庫] SKIP (all cached ok, use CSV): 53 urls\n",
            "[pref:北海道] SKIP (all cached ok, use CSV): 38 urls\n",
            "[pref:千葉] SKIP (all cached ok, use CSV): 52 urls\n",
            "[pref:和歌山] SKIP (all cached ok, use CSV): 9 urls\n",
            "[pref:埼玉] SKIP (all cached ok, use CSV): 55 urls\n",
            "[pref:大分] SKIP (all cached ok, use CSV): 12 urls\n",
            "[pref:大阪] SKIP (all cached ok, use CSV): 84 urls\n",
            "[pref:奈良] SKIP (all cached ok, use CSV): 11 urls\n",
            "[pref:宮城] SKIP (all cached ok, use CSV): 21 urls\n",
            "[pref:宮崎] SKIP (all cached ok, use CSV): 9 urls\n",
            "[pref:富山] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:山口] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:山形] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:山梨] SKIP (all cached ok, use CSV): 6 urls\n",
            "[pref:岐阜] SKIP (all cached ok, use CSV): 20 urls\n",
            "[pref:岡山] SKIP (all cached ok, use CSV): 15 urls\n",
            "[pref:岩手] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:島根] SKIP (all cached ok, use CSV): 8 urls\n",
            "[pref:広島] SKIP (all cached ok, use CSV): 25 urls\n",
            "[pref:徳島] SKIP (all cached ok, use CSV): 8 urls\n",
            "[pref:愛媛] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:愛知] SKIP (all cached ok, use CSV): 68 urls\n",
            "[pref:新潟] SKIP (all cached ok, use CSV): 19 urls\n",
            "[pref:東京] SKIP (all cached ok, use CSV): 154 urls\n",
            "[pref:栃木] SKIP (all cached ok, use CSV): 20 urls\n",
            "[pref:沖縄] SKIP (all cached ok, use CSV): 17 urls\n",
            "[pref:滋賀] SKIP (all cached ok, use CSV): 13 urls\n",
            "[pref:熊本] SKIP (all cached ok, use CSV): 14 urls\n",
            "[pref:石川] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:神奈川] SKIP (all cached ok, use CSV): 70 urls\n",
            "[pref:福井] SKIP (all cached ok, use CSV): 6 urls\n",
            "[pref:福岡] SKIP (all cached ok, use CSV): 42 urls\n",
            "[pref:福島] SKIP (all cached ok, use CSV): 15 urls\n",
            "[pref:秋田] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:群馬] SKIP (all cached ok, use CSV): 17 urls\n",
            "[pref:茨城] SKIP (all cached ok, use CSV): 23 urls\n",
            "[pref:長崎] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:長野] SKIP (all cached ok, use CSV): 16 urls\n",
            "[pref:青森] SKIP (all cached ok, use CSV): 11 urls\n",
            "[pref:静岡] SKIP (all cached ok, use CSV): 26 urls\n",
            "[pref:香川] SKIP (all cached ok, use CSV): 10 urls\n",
            "[pref:高知] SKIP (all cached ok, use CSV): 6 urls\n",
            "[pref:鳥取] SKIP (all cached ok, use CSV): 7 urls\n",
            "[pref:鹿児島] SKIP (all cached ok, use CSV): 13 urls\n",
            "proportional json files: 11\n",
            "[prop:中国ブロック] SKIP (all cached ok, use CSV): 55 urls\n",
            "[prop:九州ブロック] SKIP (all cached ok, use CSV): 98 urls\n",
            "[prop:北海道ブロック] SKIP (all cached ok, use CSV): 44 urls\n",
            "[prop:北関東ブロック] SKIP (all cached ok, use CSV): 118 urls\n",
            "[prop:北陸信越ブロック] [1/93] SKIP(cached): 石井 啓一\n",
            "[prop:北陸信越ブロック] [2/93] SKIP(cached): 輿水 恵一\n",
            "[prop:北陸信越ブロック] [3/93] SKIP(cached): 福重 隆浩\n",
            "[prop:北陸信越ブロック] [4/93] SKIP(cached): 小沼 巧\n",
            "[prop:北陸信越ブロック] [5/93] SKIP(cached): 梶岡 博樹\n",
            "[prop:北陸信越ブロック] [6/93] SKIP(cached): 小池 篤史\n",
            "[prop:北陸信越ブロック] [7/93] SKIP(cached): 福田 昭夫\n",
            "[prop:北陸信越ブロック] [8/93] SKIP(cached): 伊賀 央\n",
            "[prop:北陸信越ブロック] [9/93] SKIP(cached): 藤岡 隆雄\n",
            "[prop:北陸信越ブロック] [10/93] SKIP(cached): 河村 正剛\n",
            "[prop:北陸信越ブロック] [11/93] SKIP(cached): 長谷川 嘉一\n",
            "[prop:北陸信越ブロック] [12/93] SKIP(cached): 山田 博規\n",
            "[prop:北陸信越ブロック] [13/93] OK: 武正 公一\n",
            "[prop:北陸信越ブロック] [14/93] OK: 竹内 千春\n",
            "[prop:北陸信越ブロック] [15/93] OK: 枝野 幸男\n",
            "[prop:北陸信越ブロック] [16/93] OK: 大島 敦\n",
            "[prop:北陸信越ブロック] [17/93] OK: 小宮山 泰子\n",
            "[prop:北陸信越ブロック] [18/93] OK: 市来 伴子\n",
            "[prop:北陸信越ブロック] [19/93] OK: 杉村 慎治\n",
            "[prop:北陸信越ブロック] [20/93] OK: 坂本 祐之輔\n",
            "[prop:北陸信越ブロック] [21/93] OK: 島田 誠\n",
            "[prop:北陸信越ブロック] [22/93] OK: 森田 俊和\n",
            "[prop:北陸信越ブロック] [23/93] OK: 小山田 経子\n",
            "[prop:北陸信越ブロック] [24/93] OK: 三角 創太\n",
            "[prop:北陸信越ブロック] [25/93] OK: 木村 誠\n",
            "[prop:北陸信越ブロック] [26/93] OK: 伊藤 純子\n",
            "[prop:北陸信越ブロック] [27/93] OK: 五位野 一法\n",
            "[prop:北陸信越ブロック] [28/93] OK: 武藤 かず子\n",
            "[prop:北陸信越ブロック] [29/93] OK: 田所 嘉徳\n",
            "[prop:北陸信越ブロック] [30/93] OK: 葉梨 康弘\n",
            "[prop:北陸信越ブロック] [31/93] OK: 梶山 弘志\n",
            "[prop:北陸信越ブロック] [32/93] OK: 鈴木 拓海\n",
            "[prop:北陸信越ブロック] [33/93] OK: 国光 文乃\n",
            "[prop:北陸信越ブロック] [34/93] OK: 永岡 桂子\n",
            "[prop:北陸信越ブロック] [35/93] OK: 船田 元\n",
            "[prop:北陸信越ブロック] [36/93] OK: 五十嵐 清\n",
            "[prop:北陸信越ブロック] [37/93] OK: 簗 和生\n",
            "[prop:北陸信越ブロック] [38/93] OK: 石坂 太\n",
            "[prop:北陸信越ブロック] [39/93] OK: 茂木 敏充\n",
            "[prop:北陸信越ブロック] [40/93] OK: 中曽根 康隆\n",
            "[prop:北陸信越ブロック] [41/93] OK: 井野 俊郎\n",
            "[prop:北陸信越ブロック] [42/93] OK: 笹川 博義\n",
            "[prop:北陸信越ブロック] [43/93] OK: 福田 達夫\n",
            "[prop:北陸信越ブロック] [44/93] OK: 小渕 優子\n",
            "[prop:北陸信越ブロック] [45/93] OK: 村井 英樹\n",
            "[prop:北陸信越ブロック] [46/93] OK: 新藤 義孝\n",
            "[prop:北陸信越ブロック] [47/93] OK: 黄川田 仁志\n",
            "[prop:北陸信越ブロック] [48/93] OK: 穂坂 泰\n",
            "[prop:北陸信越ブロック] [49/93] OK: 井原 隆\n",
            "[prop:北陸信越ブロック] [50/93] OK: 尾花 瑛仁\n",
            "[prop:北陸信越ブロック] [51/93] OK: 中野 英幸\n",
            "[prop:北陸信越ブロック] [52/93] OK: 柴山 昌彦\n",
            "[prop:北陸信越ブロック] [53/93] OK: 大塚 拓\n",
            "[prop:北陸信越ブロック] [54/93] OK: 山口 晋\n",
            "[prop:北陸信越ブロック] [55/93] OK: 野中 厚\n",
            "[prop:北陸信越ブロック] [56/93] OK: 三ツ林 裕巳\n",
            "[prop:北陸信越ブロック] [57/93] OK: 藤田 誠\n",
            "[prop:北陸信越ブロック] [58/93] OK: 田中 良生\n",
            "[prop:北陸信越ブロック] [59/93] OK: 中根 一幸\n",
            "[prop:北陸信越ブロック] [60/93] OK: 西條 昌良\n",
            "[prop:北陸信越ブロック] [61/93] OK: 石川 昭政\n",
            "[prop:北陸信越ブロック] [62/93] OK: 尾身 朝子\n",
            "[prop:北陸信越ブロック] [63/93] OK: 前川 恵\n",
            "[prop:北陸信越ブロック] [64/93] OK: 田島 宏樹\n",
            "[prop:北陸信越ブロック] [65/93] OK: 冨山 ひで子\n",
            "[prop:北陸信越ブロック] [66/93] OK: 増田 勝\n",
            "[prop:北陸信越ブロック] [67/93] OK: 柏倉 祐司\n",
            "[prop:北陸信越ブロック] [68/93] OK: 高橋 英明\n",
            "[prop:北陸信越ブロック] [69/93] OK: 伊勢田 享子\n",
            "[prop:北陸信越ブロック] [70/93] OK: 津田 賢伯\n",
            "[prop:北陸信越ブロック] [71/93] OK: 南原 竜樹\n",
            "[prop:北陸信越ブロック] [72/93] OK: 高井 崇志\n",
            "[prop:北陸信越ブロック] [73/93] OK: 山越 光敏\n",
            "[prop:北陸信越ブロック] [74/93] OK: 星 孝典\n",
            "[prop:北陸信越ブロック] [75/93] OK: 塩川 鉄也\n",
            "[prop:北陸信越ブロック] [76/93] OK: 梅村 早江子\n",
            "[prop:北陸信越ブロック] [77/93] OK: 豊田 真由子\n",
            "[prop:北陸信越ブロック] [78/93] OK: 大森 紀明\n",
            "[prop:北陸信越ブロック] [79/93] OK: 青木 ひとみ\n",
            "[prop:北陸信越ブロック] [80/93] OK: 川端 絢美\n",
            "[prop:北陸信越ブロック] [81/93] OK: 長島 美子\n",
            "[prop:北陸信越ブロック] [82/93] OK: 斎藤 真衣\n",
            "[prop:北陸信越ブロック] [83/93] OK: 堀越 麻紀\n",
            "[prop:北陸信越ブロック] [84/93] OK: 浅野 哲\n",
            "[prop:北陸信越ブロック] [85/93] OK: 岸田 光広\n",
            "[prop:北陸信越ブロック] [86/93] OK: 鈴木 義弘\n",
            "[prop:北陸信越ブロック] [87/93] OK: 谷川 祐一\n",
            "[prop:北陸信越ブロック] [88/93] OK: 寺田 和史\n",
            "[prop:北陸信越ブロック] [89/93] OK: 橋本 幹彦\n",
            "[prop:北陸信越ブロック] [90/93] OK: 原 和隆\n",
            "[prop:北陸信越ブロック] [91/93] OK: 布施 卓人\n",
            "[prop:北陸信越ブロック] [92/93] OK: 細谷 勇人\n",
            "[prop:北陸信越ブロック] [93/93] OK: 小泉 俊明\n",
            "[prop:南関東ブロック] [1/103] SKIP(cached): 三好 諒\n",
            "[prop:南関東ブロック] [2/103] OK: 山本 譲司\n",
            "[prop:南関東ブロック] [3/103] OK: 有野 洋輔\n",
            "[prop:南関東ブロック] [4/103] OK: 角田 秀穂\n",
            "[prop:南関東ブロック] [5/103] OK: 沼崎 満子\n",
            "[prop:南関東ブロック] [6/103] OK: 原田 直樹\n",
            "[prop:南関東ブロック] [7/103] OK: 田嶋 要\n",
            "[prop:南関東ブロック] [8/103] OK: 佐藤 由美\n",
            "[prop:南関東ブロック] [9/103] OK: 岡島 一正\n",
            "[prop:南関東ブロック] [10/103] OK: 水沼 秀幸\n",
            "[prop:南関東ブロック] [11/103] OK: 矢崎 堅太郎\n",
            "[prop:南関東ブロック] [12/103] OK: 安藤 淳子\n",
            "[prop:南関東ブロック] [13/103] OK: 本庄 知史\n",
            "[prop:南関東ブロック] [14/103] OK: 奥野 総一郎\n",
            "[prop:南関東ブロック] [15/103] OK: 谷田川 元\n",
            "[prop:南関東ブロック] [16/103] OK: 多ケ谷 亮\n",
            "[prop:南関東ブロック] [17/103] OK: 宮川 伸\n",
            "[prop:南関東ブロック] [18/103] OK: 篠原 豪\n",
            "[prop:南関東ブロック] [19/103] OK: 柳家 東三楼\n",
            "[prop:南関東ブロック] [20/103] OK: 中村 武人\n",
            "[prop:南関東ブロック] [21/103] OK: 早稲田 夕季\n",
            "[prop:南関東ブロック] [22/103] OK: 山崎 誠\n",
            "[prop:南関東ブロック] [23/103] OK: 青柳 陽一郎\n",
            "[prop:南関東ブロック] [24/103] OK: 中谷 一馬\n",
            "[prop:南関東ブロック] [25/103] OK: 江田 憲司\n",
            "[prop:南関東ブロック] [26/103] OK: 笠 浩史\n",
            "[prop:南関東ブロック] [27/103] OK: 阿部 知子\n",
            "[prop:南関東ブロック] [28/103] OK: 太 栄志\n",
            "[prop:南関東ブロック] [29/103] OK: 長友 克洋\n",
            "[prop:南関東ブロック] [30/103] OK: 後藤 祐一\n",
            "[prop:南関東ブロック] [31/103] OK: 佐々木 奈保美\n",
            "[prop:南関東ブロック] [32/103] OK: 宗野 創\n",
            "[prop:南関東ブロック] [33/103] OK: 大塚 小百合\n",
            "[prop:南関東ブロック] [34/103] OK: 中島 克仁\n",
            "[prop:南関東ブロック] [35/103] OK: 石塚 貞通\n",
            "[prop:南関東ブロック] [36/103] OK: 田沼 隆志\n",
            "[prop:南関東ブロック] [37/103] OK: 浅川 義治\n",
            "[prop:南関東ブロック] [38/103] OK: 久坂 くにえ\n",
            "[prop:南関東ブロック] [39/103] OK: 金村 龍那\n",
            "[prop:南関東ブロック] [40/103] OK: 横田 光弘\n",
            "[prop:南関東ブロック] [41/103] OK: 添田 勝\n",
            "[prop:南関東ブロック] [42/103] OK: 金子 洋一\n",
            "[prop:南関東ブロック] [43/103] OK: 工藤 聖子\n",
            "[prop:南関東ブロック] [44/103] OK: 宮本 寛之\n",
            "[prop:南関東ブロック] [45/103] OK: 中谷 めぐみ\n",
            "[prop:南関東ブロック] [46/103] OK: 室井 一真\n",
            "[prop:南関東ブロック] [47/103] OK: 和田 武士\n",
            "[prop:南関東ブロック] [48/103] OK: 久野 晋作\n",
            "[prop:南関東ブロック] [49/103] OK: 岡野 純子\n",
            "[prop:南関東ブロック] [50/103] OK: 片山 智絵\n",
            "[prop:南関東ブロック] [51/103] OK: 中村 太一\n",
            "[prop:南関東ブロック] [52/103] OK: 西岡 義高\n",
            "[prop:南関東ブロック] [53/103] OK: 二宮 研\n",
            "[prop:南関東ブロック] [54/103] OK: 林田 章裕\n",
            "[prop:南関東ブロック] [55/103] OK: 深作 ヘスス\n",
            "[prop:南関東ブロック] [56/103] OK: 武藤 雄大\n",
            "[prop:南関東ブロック] [57/103] OK: 山口 翔平\n",
            "[prop:南関東ブロック] [58/103] OK: 梅原 克彦\n",
            "[prop:南関東ブロック] [59/103] OK: 冨田 格\n",
            "[prop:南関東ブロック] [60/103] OK: 河合 道雄\n",
            "[prop:南関東ブロック] [61/103] OK: 山田 瑛理\n",
            "[prop:南関東ブロック] [62/103] OK: 小林 修平\n",
            "[prop:南関東ブロック] [63/103] OK: 佐々木 克己\n",
            "[prop:南関東ブロック] [64/103] OK: 門山 宏哲\n",
            "[prop:南関東ブロック] [65/103] OK: 小林 鷹之\n",
            "[prop:南関東ブロック] [66/103] OK: 松野 博一\n",
            "[prop:南関東ブロック] [67/103] OK: 鹿嶋 祐介\n",
            "[prop:南関東ブロック] [68/103] OK: 英利 アルフィヤ\n",
            "[prop:南関東ブロック] [69/103] OK: 斎藤 健\n",
            "[prop:南関東ブロック] [70/103] OK: 松本 泉\n",
            "[prop:南関東ブロック] [71/103] OK: 田宮 寿人\n",
            "[prop:南関東ブロック] [72/103] OK: 小池 正昭\n",
            "[prop:南関東ブロック] [73/103] OK: 浜田 靖一\n",
            "[prop:南関東ブロック] [74/103] OK: 松本 尚\n",
            "[prop:南関東ブロック] [75/103] OK: 長野 春信\n",
            "[prop:南関東ブロック] [76/103] OK: 丸尾 南都子\n",
            "[prop:南関東ブロック] [77/103] OK: 新田 章文\n",
            "[prop:南関東ブロック] [78/103] OK: 中西 健治\n",
            "[prop:南関東ブロック] [79/103] OK: 永田 磨梨奈\n",
            "[prop:南関東ブロック] [80/103] OK: 坂井 学\n",
            "[prop:南関東ブロック] [81/103] OK: 古川 直季\n",
            "[prop:南関東ブロック] [82/103] OK: 鈴木 馨祐\n",
            "[prop:南関東ブロック] [83/103] OK: 三谷 英弘\n",
            "[prop:南関東ブロック] [84/103] OK: 上原 正裕\n",
            "[prop:南関東ブロック] [85/103] OK: 星野 剛士\n",
            "[prop:南関東ブロック] [86/103] OK: 丸田 康一郎\n",
            "[prop:南関東ブロック] [87/103] OK: 赤間 二郎\n",
            "[prop:南関東ブロック] [88/103] OK: 河野 太郎\n",
            "[prop:南関東ブロック] [89/103] OK: 佐藤 主迪\n",
            "[prop:南関東ブロック] [90/103] OK: 牧島 かれん\n",
            "[prop:南関東ブロック] [91/103] OK: 山際 大志郎\n",
            "[prop:南関東ブロック] [92/103] OK: 草間 剛\n",
            "[prop:南関東ブロック] [93/103] OK: 金沢 結衣\n",
            "[prop:南関東ブロック] [94/103] OK: 中谷 真一\n",
            "[prop:南関東ブロック] [95/103] OK: 堀内 詔子\n",
            "[prop:南関東ブロック] [96/103] OK: 伊藤 聡\n",
            "[prop:南関東ブロック] [97/103] OK: 文月 涼\n",
            "[prop:南関東ブロック] [98/103] OK: 岩崎 比菜\n",
            "[prop:南関東ブロック] [99/103] OK: 畑野 君枝\n",
            "[prop:南関東ブロック] [100/103] OK: 斉藤 和子\n",
            "[prop:南関東ブロック] [101/103] OK: 飯田 能生\n",
            "[prop:南関東ブロック] [102/103] OK: 川田 龍平\n",
            "[prop:南関東ブロック] [103/103] OK: 高橋 宏\n",
            "[prop:四国ブロック] [1/33] OK: 三谷 祥子\n",
            "[prop:四国ブロック] [2/33] OK: 山崎 正恭\n",
            "[prop:四国ブロック] [3/33] OK: 高橋 永\n",
            "[prop:四国ブロック] [4/33] OK: 小川 淳也\n",
            "[prop:四国ブロック] [5/33] OK: 白石 洋一\n",
            "[prop:四国ブロック] [6/33] OK: 萩原 旭人\n",
            "[prop:四国ブロック] [7/33] OK: 田所 裕介\n",
            "[prop:四国ブロック] [8/33] OK: 原田 慎太郎\n",
            "[prop:四国ブロック] [9/33] OK: 金城 幹泰\n",
            "[prop:四国ブロック] [10/33] OK: 中根 耕作\n",
            "[prop:四国ブロック] [11/33] OK: 吉田 知代\n",
            "[prop:四国ブロック] [12/33] OK: 細川 修平\n",
            "[prop:四国ブロック] [13/33] OK: 飯泉 嘉門\n",
            "[prop:四国ブロック] [14/33] OK: 石井 智恵\n",
            "[prop:四国ブロック] [15/33] OK: 川崎 智光\n",
            "[prop:四国ブロック] [16/33] OK: 前田 強\n",
            "[prop:四国ブロック] [17/33] OK: 久保 耕次郎\n",
            "[prop:四国ブロック] [18/33] OK: 仁木 博文\n",
            "[prop:四国ブロック] [19/33] OK: 平井 卓也\n",
            "[prop:四国ブロック] [20/33] OK: 瀬戸 隆一\n",
            "[prop:四国ブロック] [21/33] OK: 大野 敬太郎\n",
            "[prop:四国ブロック] [22/33] OK: 塩崎 彰久\n",
            "[prop:四国ブロック] [23/33] OK: 井原 巧\n",
            "[prop:四国ブロック] [24/33] OK: 長谷川 淳二\n",
            "[prop:四国ブロック] [25/33] OK: 中谷 元\n",
            "[prop:四国ブロック] [26/33] OK: 尾﨑 正直\n",
            "[prop:四国ブロック] [27/33] OK: 村上 誠一郎\n",
            "[prop:四国ブロック] [28/33] OK: 中山 展宏\n",
            "[prop:四国ブロック] [29/33] OK: 岡山 正樹\n",
            "[prop:四国ブロック] [30/33] OK: 宮本 直樹\n",
            "[prop:四国ブロック] [31/33] OK: 宇佐美 伸次\n",
            "[prop:四国ブロック] [32/33] OK: 高橋 央\n",
            "[prop:四国ブロック] [33/33] OK: 仙波 理子\n",
            "[prop:東京ブロック] [1/57] SKIP(cached): 藤野 保史\n",
            "[prop:東京ブロック] [2/57] OK: 平 あや子\n",
            "[prop:東京ブロック] [3/57] OK: 三井田 孝欧\n",
            "[prop:東京ブロック] [4/57] OK: 小竹 凱\n",
            "[prop:東京ブロック] [5/57] OK: 野村 泰暉\n",
            "[prop:東京ブロック] [6/57] OK: 花岡 明久\n",
            "[prop:東京ブロック] [7/57] OK: 山中 俊祐\n",
            "[prop:東京ブロック] [8/57] OK: 山本 圭太\n",
            "[prop:東京ブロック] [9/57] OK: 国定 勇人\n",
            "[prop:東京ブロック] [10/57] OK: 斎藤 洋明\n",
            "[prop:東京ブロック] [11/57] OK: 上田 英俊\n",
            "[prop:東京ブロック] [12/57] OK: 橘 慶一郎\n",
            "[prop:東京ブロック] [13/57] OK: 小森 卓郎\n",
            "[prop:東京ブロック] [14/57] OK: 佐々木 紀\n",
            "[prop:東京ブロック] [15/57] OK: 西田 昭二\n",
            "[prop:東京ブロック] [16/57] OK: 稲田 朋美\n",
            "[prop:東京ブロック] [17/57] OK: 井出 庸生\n",
            "[prop:東京ブロック] [18/57] OK: 後藤 茂之\n",
            "[prop:東京ブロック] [19/57] OK: 宮下 一郎\n",
            "[prop:東京ブロック] [20/57] OK: 田畑 裕明\n",
            "[prop:東京ブロック] [21/57] OK: 内山 航\n",
            "[prop:東京ブロック] [22/57] OK: 鷲尾 英一郎\n",
            "[prop:東京ブロック] [23/57] OK: 高鳥 修一\n",
            "[prop:東京ブロック] [24/57] OK: 中田 宏\n",
            "[prop:東京ブロック] [25/57] OK: 若林 健太\n",
            "[prop:東京ブロック] [26/57] OK: 藤田 ひかる\n",
            "[prop:東京ブロック] [27/57] OK: 今 洋佑\n",
            "[prop:東京ブロック] [28/57] OK: 古井 康介\n",
            "[prop:東京ブロック] [29/57] OK: 五十田 裕子\n",
            "[prop:東京ブロック] [30/57] OK: 蓮池 透\n",
            "[prop:東京ブロック] [31/57] OK: 川 裕一郎\n",
            "[prop:東京ブロック] [32/57] OK: 藤本 一希\n",
            "[prop:東京ブロック] [33/57] OK: 斉藤 匠\n",
            "[prop:東京ブロック] [34/57] OK: 高岩 勝人\n",
            "[prop:東京ブロック] [35/57] OK: 中川 宏昌\n",
            "[prop:東京ブロック] [36/57] OK: 西村 智奈美\n",
            "[prop:東京ブロック] [37/57] OK: 菊田 真紀子\n",
            "[prop:東京ブロック] [38/57] OK: 黒岩 宇洋\n",
            "[prop:東京ブロック] [39/57] OK: 米山 隆一\n",
            "[prop:東京ブロック] [40/57] OK: 梅谷 守\n",
            "[prop:東京ブロック] [41/57] OK: 山 登志浩\n",
            "[prop:東京ブロック] [42/57] OK: 越川 康晴\n",
            "[prop:東京ブロック] [43/57] OK: 近藤 和也\n",
            "[prop:東京ブロック] [44/57] OK: 波多野 翼\n",
            "[prop:東京ブロック] [45/57] OK: 辻 英之\n",
            "[prop:東京ブロック] [46/57] OK: 篠原 孝\n",
            "[prop:東京ブロック] [47/57] OK: 下条 みつ\n",
            "[prop:東京ブロック] [48/57] OK: 神津 健\n",
            "[prop:東京ブロック] [49/57] OK: 福田 淳太\n",
            "[prop:東京ブロック] [50/57] OK: 伊藤 和成\n",
            "[prop:東京ブロック] [51/57] OK: 金井 典子\n",
            "[prop:東京ブロック] [52/57] OK: 小林 誠\n",
            "[prop:東京ブロック] [53/57] OK: 若狭 清史\n",
            "[prop:東京ブロック] [54/57] OK: 手塚 大輔\n",
            "[prop:東京ブロック] [55/57] OK: 佐野 秀光\n",
            "[prop:東京ブロック] [56/57] OK: 高橋 忠男\n",
            "[prop:東京ブロック] [57/57] OK: 斎藤 幸男\n",
            "[prop:東北ブロック] [1/67] SKIP(cached): 佐原 若子\n",
            "[prop:東北ブロック] [2/67] OK: 二藤部 冬馬\n",
            "[prop:東北ブロック] [3/67] OK: 庄子 賢一\n",
            "[prop:東北ブロック] [4/67] OK: 有田 芳生\n",
            "[prop:東北ブロック] [5/67] OK: 升田 世喜男\n",
            "[prop:東北ブロック] [6/67] OK: 松尾 和彦\n",
            "[prop:東北ブロック] [7/67] OK: 岡田 華子\n",
            "[prop:東北ブロック] [8/67] OK: 階 猛\n",
            "[prop:東北ブロック] [9/67] OK: 小沢 一郎\n",
            "[prop:東北ブロック] [10/67] OK: 岡本 章子\n",
            "[prop:東北ブロック] [11/67] OK: 鎌田 さゆり\n",
            "[prop:東北ブロック] [12/67] OK: 柳沢 剛\n",
            "[prop:東北ブロック] [13/67] OK: 安住 淳\n",
            "[prop:東北ブロック] [14/67] OK: 境 恒春\n",
            "[prop:東北ブロック] [15/67] OK: 早川 周作\n",
            "[prop:東北ブロック] [16/67] OK: 緑川 貴士\n",
            "[prop:東北ブロック] [17/67] OK: 原田 和広\n",
            "[prop:東北ブロック] [18/67] OK: 落合 拓磨\n",
            "[prop:東北ブロック] [19/67] OK: 金子 恵美\n",
            "[prop:東北ブロック] [20/67] OK: 玄葉 光一郎\n",
            "[prop:東北ブロック] [21/67] OK: 小熊 慎司\n",
            "[prop:東北ブロック] [22/67] OK: 斎藤 裕喜\n",
            "[prop:東北ブロック] [23/67] OK: 江渡 聡徳\n",
            "[prop:東北ブロック] [24/67] OK: 津島 淳\n",
            "[prop:東北ブロック] [25/67] OK: 神田 潤一\n",
            "[prop:東北ブロック] [26/67] OK: 木村 次郎\n",
            "[prop:東北ブロック] [27/67] OK: 米内 紘正\n",
            "[prop:東北ブロック] [28/67] OK: 鈴木 俊一\n",
            "[prop:東北ブロック] [29/67] OK: 藤原 崇\n",
            "[prop:東北ブロック] [30/67] OK: 土井 亨\n",
            "[prop:東北ブロック] [31/67] OK: 渡辺 勝幸\n",
            "[prop:東北ブロック] [32/67] OK: 西村 明宏\n",
            "[prop:東北ブロック] [33/67] OK: 森下 千里\n",
            "[prop:東北ブロック] [34/67] OK: 小野寺 五典\n",
            "[prop:東北ブロック] [35/67] OK: 冨樫 博之\n",
            "[prop:東北ブロック] [36/67] OK: 福原 淳嗣\n",
            "[prop:東北ブロック] [37/67] OK: 御法川 信英\n",
            "[prop:東北ブロック] [38/67] OK: 遠藤 寛明\n",
            "[prop:東北ブロック] [39/67] OK: 鈴木 憲和\n",
            "[prop:東北ブロック] [40/67] OK: 加藤 鮎子\n",
            "[prop:東北ブロック] [41/67] OK: 西山 尚利\n",
            "[prop:東北ブロック] [42/67] OK: 根本 拓\n",
            "[prop:東北ブロック] [43/67] OK: 上杉 謙太郎\n",
            "[prop:東北ブロック] [44/67] OK: 坂本 竜太郎\n",
            "[prop:東北ブロック] [45/67] OK: 伊藤 信太郎\n",
            "[prop:東北ブロック] [46/67] OK: 菅家 一郎\n",
            "[prop:東北ブロック] [47/67] OK: 秋葉 賢也\n",
            "[prop:東北ブロック] [48/67] OK: 愛知 治郎\n",
            "[prop:東北ブロック] [49/67] OK: 和田 政宗\n",
            "[prop:東北ブロック] [50/67] OK: ローレンス 綾子\n",
            "[prop:東北ブロック] [51/67] OK: 大山 里幸子\n",
            "[prop:東北ブロック] [52/67] OK: 高橋 千鶴子\n",
            "[prop:東北ブロック] [53/67] OK: 吉田 恭子\n",
            "[prop:東北ブロック] [54/67] OK: 遠藤 芳孝\n",
            "[prop:東北ブロック] [55/67] OK: 林 拓海\n",
            "[prop:東北ブロック] [56/67] OK: 金濱 亨\n",
            "[prop:東北ブロック] [57/67] OK: 菊池 大二郎\n",
            "[prop:東北ブロック] [58/67] OK: 喜多 恒介\n",
            "[prop:東北ブロック] [59/67] OK: 木村 佐知子\n",
            "[prop:東北ブロック] [60/67] OK: 佐々木 真琴\n",
            "[prop:東北ブロック] [61/67] OK: 佐藤 理々香\n",
            "[prop:東北ブロック] [62/67] OK: 村岡 敏英\n",
            "[prop:東北ブロック] [63/67] OK: 山口 洋太\n",
            "[prop:東北ブロック] [64/67] OK: 小沢 倫平\n",
            "[prop:東北ブロック] [65/67] OK: 高橋 浩司\n",
            "[prop:東北ブロック] [66/67] OK: 早坂 敦\n",
            "[prop:東北ブロック] [67/67] OK: 松浦 大悟\n",
            "[prop:東海ブロック] [1/109] SKIP(cached): 北野谷 富子\n",
            "[prop:東海ブロック] [2/109] OK: 柴田 将平\n",
            "[prop:東海ブロック] [3/109] OK: 仙田 晃宏\n",
            "[prop:東海ブロック] [4/109] OK: 田中 健\n",
            "[prop:東海ブロック] [5/109] OK: 丹野 みどり\n",
            "[prop:東海ブロック] [6/109] OK: 野村 美穂\n",
            "[prop:東海ブロック] [7/109] OK: 日野 紗里亜\n",
            "[prop:東海ブロック] [8/109] OK: 福田 徹\n",
            "[prop:東海ブロック] [9/109] OK: 藤田 大助\n",
            "[prop:東海ブロック] [10/109] OK: 古川 元久\n",
            "[prop:東海ブロック] [11/109] OK: 三嶋 竜平\n",
            "[prop:東海ブロック] [12/109] OK: 吉田 企貴\n",
            "[prop:東海ブロック] [13/109] OK: 須田 英太郎\n",
            "[prop:東海ブロック] [14/109] OK: 山本 左近\n",
            "[prop:東海ブロック] [15/109] OK: 野田 聖子\n",
            "[prop:東海ブロック] [16/109] OK: 棚橋 泰文\n",
            "[prop:東海ブロック] [17/109] OK: 武藤 容治\n",
            "[prop:東海ブロック] [18/109] OK: 加藤 大博\n",
            "[prop:東海ブロック] [19/109] OK: 上川 陽子\n",
            "[prop:東海ブロック] [20/109] OK: 井林 辰憲\n",
            "[prop:東海ブロック] [21/109] OK: 山本 裕三\n",
            "[prop:東海ブロック] [22/109] OK: 深沢 陽一\n",
            "[prop:東海ブロック] [23/109] OK: 細野 豪志\n",
            "[prop:東海ブロック] [24/109] OK: 勝俣 孝明\n",
            "[prop:東海ブロック] [25/109] OK: 城内 実\n",
            "[prop:東海ブロック] [26/109] OK: 稲葉 大輔\n",
            "[prop:東海ブロック] [27/109] OK: 熊田 裕通\n",
            "[prop:東海ブロック] [28/109] OK: 辻 秀樹\n",
            "[prop:東海ブロック] [29/109] OK: 水野 良彦\n",
            "[prop:東海ブロック] [30/109] OK: 工藤 彰三\n",
            "[prop:東海ブロック] [31/109] OK: 岡本 康宏\n",
            "[prop:東海ブロック] [32/109] OK: 丹羽 秀樹\n",
            "[prop:東海ブロック] [33/109] OK: 鈴木 淳司\n",
            "[prop:東海ブロック] [34/109] OK: 伊藤 忠彦\n",
            "[prop:東海ブロック] [35/109] OK: 長坂 康正\n",
            "[prop:東海ブロック] [36/109] OK: 若山 慎司\n",
            "[prop:東海ブロック] [37/109] OK: 藤沢 忠盛\n",
            "[prop:東海ブロック] [38/109] OK: 青山 周平\n",
            "[prop:東海ブロック] [39/109] OK: 石井 拓\n",
            "[prop:東海ブロック] [40/109] OK: 今枝 宗一郎\n",
            "[prop:東海ブロック] [41/109] OK: 根本 幸典\n",
            "[prop:東海ブロック] [42/109] OK: 山下 史守朗\n",
            "[prop:東海ブロック] [43/109] OK: 田村 憲久\n",
            "[prop:東海ブロック] [44/109] OK: 川崎 秀人\n",
            "[prop:東海ブロック] [45/109] OK: 石原 正敬\n",
            "[prop:東海ブロック] [46/109] OK: 鈴木 英敬\n",
            "[prop:東海ブロック] [47/109] OK: 細田 健一\n",
            "[prop:東海ブロック] [48/109] OK: 中川 貴元\n",
            "[prop:東海ブロック] [49/109] OK: 斉藤 里恵\n",
            "[prop:東海ブロック] [50/109] OK: 長田 紘一郎\n",
            "[prop:東海ブロック] [51/109] OK: 世古 万美子\n",
            "[prop:東海ブロック] [52/109] OK: 松本 忠真\n",
            "[prop:東海ブロック] [53/109] OK: 中川 康洋\n",
            "[prop:東海ブロック] [54/109] OK: 西園 勝秀\n",
            "[prop:東海ブロック] [55/109] OK: 犬飼 明佳\n",
            "[prop:東海ブロック] [56/109] OK: 服部 学\n",
            "[prop:東海ブロック] [57/109] OK: 今井 雅人\n",
            "[prop:東海ブロック] [58/109] OK: 真野 哲\n",
            "[prop:東海ブロック] [59/109] OK: 鈴木 岳幸\n",
            "[prop:東海ブロック] [60/109] OK: 小山 展弘\n",
            "[prop:東海ブロック] [61/109] OK: 中村 正善\n",
            "[prop:東海ブロック] [62/109] OK: 渡辺 周\n",
            "[prop:東海ブロック] [63/109] OK: 源馬 謙太郎\n",
            "[prop:東海ブロック] [64/109] OK: 吉田 統彦\n",
            "[prop:東海ブロック] [65/109] OK: 近藤 昭一\n",
            "[prop:東海ブロック] [66/109] OK: 牧 義夫\n",
            "[prop:東海ブロック] [67/109] OK: 西川 厚志\n",
            "[prop:東海ブロック] [68/109] OK: 国崎 信江\n",
            "[prop:東海ブロック] [69/109] OK: 伴野 豊\n",
            "[prop:東海ブロック] [70/109] OK: 岡本 充功\n",
            "[prop:東海ブロック] [71/109] OK: 藤原 規真\n",
            "[prop:東海ブロック] [72/109] OK: 重徳 和彦\n",
            "[prop:東海ブロック] [73/109] OK: 大西 健介\n",
            "[prop:東海ブロック] [74/109] OK: 大嶽 理恵\n",
            "[prop:東海ブロック] [75/109] OK: 小山 千帆\n",
            "[prop:東海ブロック] [76/109] OK: 松田 功\n",
            "[prop:東海ブロック] [77/109] OK: 福森 和歌子\n",
            "[prop:東海ブロック] [78/109] OK: 下野 幸助\n",
            "[prop:東海ブロック] [79/109] OK: 山田 良司\n",
            "[prop:東海ブロック] [80/109] OK: 皆川 雅一\n",
            "[prop:東海ブロック] [81/109] OK: 中田 千代\n",
            "[prop:東海ブロック] [82/109] OK: 浦上 奈々\n",
            "[prop:東海ブロック] [83/109] OK: 杉本 和巳\n",
            "[prop:東海ブロック] [84/109] OK: 関 健一郎\n",
            "[prop:東海ブロック] [85/109] OK: 有本 香\n",
            "[prop:東海ブロック] [86/109] OK: 中川 健一\n",
            "[prop:東海ブロック] [87/109] OK: 伊藤 昌志\n",
            "[prop:東海ブロック] [88/109] OK: 本村 伸子\n",
            "[prop:東海ブロック] [89/109] OK: 須山 初美\n",
            "[prop:東海ブロック] [90/109] OK: 阪口 直人\n",
            "[prop:東海ブロック] [91/109] OK: 辻 恵\n",
            "[prop:東海ブロック] [92/109] OK: 鈴木 智\n",
            "[prop:東海ブロック] [93/109] OK: 上村 英明\n",
            "[prop:東海ブロック] [94/109] OK: 伊藤 恵介\n",
            "[prop:東海ブロック] [95/109] OK: 新谷 恵\n",
            "[prop:東海ブロック] [96/109] OK: 渡辺 藍理\n",
            "[prop:東海ブロック] [97/109] OK: 高田 晃宏\n",
            "[prop:東海ブロック] [98/109] OK: 中川 博登\n",
            "[prop:東海ブロック] [99/109] OK: 水谷 幸泰\n",
            "[prop:東海ブロック] [100/109] OK: 山内 遼平\n",
            "[prop:東海ブロック] [101/109] OK: 大西 雅人\n",
            "[prop:東海ブロック] [102/109] OK: 梅村 忠司\n",
            "[prop:東海ブロック] [103/109] OK: 平岩 征樹\n",
            "[prop:東海ブロック] [104/109] OK: 志村 康博\n",
            "[prop:東海ブロック] [105/109] OK: 田中 克和\n",
            "[prop:東海ブロック] [106/109] OK: 橋本 勉\n",
            "[prop:東海ブロック] [107/109] OK: 竹上 裕子\n",
            "[prop:東海ブロック] [108/109] OK: 前田 雄吉\n",
            "[prop:東海ブロック] [109/109] OK: 河村 たかし\n",
            "[prop:近畿ブロック] [1/138] SKIP(cached): 西尾 慧吾\n",
            "[prop:近畿ブロック] [2/138] OK: 辰巳 孝太郎\n",
            "[prop:近畿ブロック] [3/138] OK: 堀川 朗子\n",
            "[prop:近畿ブロック] [4/138] OK: 清水 忠史\n",
            "[prop:近畿ブロック] [5/138] OK: 冨士谷 香恵子\n",
            "[prop:近畿ブロック] [6/138] OK: 石川 勝\n",
            "[prop:近畿ブロック] [7/138] OK: 池上 和日子\n",
            "[prop:近畿ブロック] [8/138] OK: 谷 浩一郎\n",
            "[prop:近畿ブロック] [9/138] OK: 林元 政子\n",
            "[prop:近畿ブロック] [10/138] OK: 黒川 洋司\n",
            "[prop:近畿ブロック] [11/138] OK: 黒石 隆太\n",
            "[prop:近畿ブロック] [12/138] OK: 油谷 聖一郎\n",
            "[prop:近畿ブロック] [13/138] OK: 大石 晃子\n",
            "[prop:近畿ブロック] [14/138] OK: 八幡 愛\n",
            "[prop:近畿ブロック] [15/138] OK: 長谷川 羽衣子\n",
            "[prop:近畿ブロック] [16/138] OK: 西郷 南海子\n",
            "[prop:近畿ブロック] [17/138] OK: 赤羽 一嘉\n",
            "[prop:近畿ブロック] [18/138] OK: 中野 洋昌\n",
            "[prop:近畿ブロック] [19/138] OK: 山本 香苗\n",
            "[prop:近畿ブロック] [20/138] OK: 伊佐 進一\n",
            "[prop:近畿ブロック] [21/138] OK: 国重 徹\n",
            "[prop:近畿ブロック] [22/138] OK: 馬淵 澄夫\n",
            "[prop:近畿ブロック] [23/138] OK: 平尾 道雄\n",
            "[prop:近畿ブロック] [24/138] OK: 早 智敬\n",
            "[prop:近畿ブロック] [25/138] OK: 平竹 耕三\n",
            "[prop:近畿ブロック] [26/138] OK: 河野 有里子\n",
            "[prop:近畿ブロック] [27/138] OK: 泉 健太\n",
            "[prop:近畿ブロック] [28/138] OK: 山井 和則\n",
            "[prop:近畿ブロック] [29/138] OK: 宇都宮 優子\n",
            "[prop:近畿ブロック] [30/138] OK: 阪本 洋三\n",
            "[prop:近畿ブロック] [31/138] OK: 尾辻 かな子\n",
            "[prop:近畿ブロック] [32/138] OK: 村上 賀厚\n",
            "[prop:近畿ブロック] [33/138] OK: 樽床 伸二\n",
            "[prop:近畿ブロック] [34/138] OK: 本多 平直\n",
            "[prop:近畿ブロック] [35/138] OK: 森山 浩行\n",
            "[prop:近畿ブロック] [36/138] OK: 小羽根 正代\n",
            "[prop:近畿ブロック] [37/138] OK: 井坂 信彦\n",
            "[prop:近畿ブロック] [38/138] OK: 船川 治郎\n",
            "[prop:近畿ブロック] [39/138] OK: 中山 高志\n",
            "[prop:近畿ブロック] [40/138] OK: 川戸 康嗣\n",
            "[prop:近畿ブロック] [41/138] OK: 桜井 周\n",
            "[prop:近畿ブロック] [42/138] OK: 岡田 悟\n",
            "[prop:近畿ブロック] [43/138] OK: 弘川 欣絵\n",
            "[prop:近畿ブロック] [44/138] OK: 橋本 慧悟\n",
            "[prop:近畿ブロック] [45/138] OK: 隠樹 圭子\n",
            "[prop:近畿ブロック] [46/138] OK: 要 友紀子\n",
            "[prop:近畿ブロック] [47/138] OK: 山本 剛義\n",
            "[prop:近畿ブロック] [48/138] OK: 堀場 幸子\n",
            "[prop:近畿ブロック] [49/138] OK: 酒井 勇輔\n",
            "[prop:近畿ブロック] [50/138] OK: 岡本 忠志\n",
            "[prop:近畿ブロック] [51/138] OK: 桂 隆俊\n",
            "[prop:近畿ブロック] [52/138] OK: 河井 昭成\n",
            "[prop:近畿ブロック] [53/138] OK: 佐藤 潤\n",
            "[prop:近畿ブロック] [54/138] OK: 塩野 智郎\n",
            "[prop:近畿ブロック] [55/138] OK: 杉本 葵\n",
            "[prop:近畿ブロック] [56/138] OK: 中原 立貴\n",
            "[prop:近畿ブロック] [57/138] OK: 林 佑美\n",
            "[prop:近畿ブロック] [58/138] OK: 前田 英倫\n",
            "[prop:近畿ブロック] [59/138] OK: 向山 好一\n",
            "[prop:近畿ブロック] [60/138] OK: 小寺 裕雄\n",
            "[prop:近畿ブロック] [61/138] OK: 石田 真敏\n",
            "[prop:近畿ブロック] [62/138] OK: 大岡 敏孝\n",
            "[prop:近畿ブロック] [63/138] OK: 上野 賢一郎\n",
            "[prop:近畿ブロック] [64/138] OK: 武村 展英\n",
            "[prop:近畿ブロック] [65/138] OK: 勝目 康\n",
            "[prop:近畿ブロック] [66/138] OK: 藤田 洋司\n",
            "[prop:近畿ブロック] [67/138] OK: 繁本 護\n",
            "[prop:近畿ブロック] [68/138] OK: 北神 圭朗\n",
            "[prop:近畿ブロック] [69/138] OK: 本田 太郎\n",
            "[prop:近畿ブロック] [70/138] OK: 園崎 弘道\n",
            "[prop:近畿ブロック] [71/138] OK: 大西 宏幸\n",
            "[prop:近畿ブロック] [72/138] OK: 柳本 顕\n",
            "[prop:近畿ブロック] [73/138] OK: 中山 泰秀\n",
            "[prop:近畿ブロック] [74/138] OK: 杉田 水脈\n",
            "[prop:近畿ブロック] [75/138] OK: 永井 正史\n",
            "[prop:近畿ブロック] [76/138] OK: 渡嘉敷 奈緒美\n",
            "[prop:近畿ブロック] [77/138] OK: 高麗 啓一郎\n",
            "[prop:近畿ブロック] [78/138] OK: 東田 淳平\n",
            "[prop:近畿ブロック] [79/138] OK: 加納 陽之助\n",
            "[prop:近畿ブロック] [80/138] OK: 松本 直高\n",
            "[prop:近畿ブロック] [81/138] OK: 北川 晋平\n",
            "[prop:近畿ブロック] [82/138] OK: 宗清 皇一\n",
            "[prop:近畿ブロック] [83/138] OK: 尾立 源幸\n",
            "[prop:近畿ブロック] [84/138] OK: 島田 智明\n",
            "[prop:近畿ブロック] [85/138] OK: 葉田 治央\n",
            "[prop:近畿ブロック] [86/138] OK: 信貴 麻美\n",
            "[prop:近畿ブロック] [87/138] OK: 内田 隆嗣\n",
            "[prop:近畿ブロック] [88/138] OK: 谷川 とむ\n",
            "[prop:近畿ブロック] [89/138] OK: 盛山 正仁\n",
            "[prop:近畿ブロック] [90/138] OK: 関 芳弘\n",
            "[prop:近畿ブロック] [91/138] OK: 藤井 比早之\n",
            "[prop:近畿ブロック] [92/138] OK: 大串 正樹\n",
            "[prop:近畿ブロック] [93/138] OK: 山田 賢司\n",
            "[prop:近畿ブロック] [94/138] OK: 西村 康稔\n",
            "[prop:近畿ブロック] [95/138] OK: 山田 基靖\n",
            "[prop:近畿ブロック] [96/138] OK: 山口 壮\n",
            "[prop:近畿ブロック] [97/138] OK: 小林 茂樹\n",
            "[prop:近畿ブロック] [98/138] OK: 田野瀬 太道\n",
            "[prop:近畿ブロック] [99/138] OK: 山本 大地\n",
            "[prop:近畿ブロック] [100/138] OK: 島田 洋一\n",
            "[prop:近畿ブロック] [101/138] OK: 佐々木 みのり\n",
            "[prop:近畿ブロック] [102/138] OK: 藤村 充亮\n",
            "[prop:近畿ブロック] [103/138] OK: 原山 大亮\n",
            "[prop:近畿ブロック] [104/138] OK: 斎藤 アレックス\n",
            "[prop:近畿ブロック] [105/138] OK: 岡屋 京佑\n",
            "[prop:近畿ブロック] [106/138] OK: 出路 真吾\n",
            "[prop:近畿ブロック] [107/138] OK: 佐々木 隆吏\n",
            "[prop:近畿ブロック] [108/138] OK: 前原 誠司\n",
            "[prop:近畿ブロック] [109/138] OK: 木村 元紀\n",
            "[prop:近畿ブロック] [110/138] OK: 井上 英孝\n",
            "[prop:近畿ブロック] [111/138] OK: 高見 亮\n",
            "[prop:近畿ブロック] [112/138] OK: 東 徹\n",
            "[prop:近畿ブロック] [113/138] OK: 美延 映夫\n",
            "[prop:近畿ブロック] [114/138] OK: 梅村 聡\n",
            "[prop:近畿ブロック] [115/138] OK: 西田 薫\n",
            "[prop:近畿ブロック] [116/138] OK: 奥下 剛光\n",
            "[prop:近畿ブロック] [117/138] OK: 漆間 譲司\n",
            "[prop:近畿ブロック] [118/138] OK: 萩原 佳\n",
            "[prop:近畿ブロック] [119/138] OK: 池下 卓\n",
            "[prop:近畿ブロック] [120/138] OK: 中司 宏\n",
            "[prop:近畿ブロック] [121/138] OK: 岩谷 良平\n",
            "[prop:近畿ブロック] [122/138] OK: 青柳 仁士\n",
            "[prop:近畿ブロック] [123/138] OK: 浦野 靖人\n",
            "[prop:近畿ブロック] [124/138] OK: 黒田 征樹\n",
            "[prop:近畿ブロック] [125/138] OK: 遠藤 敬\n",
            "[prop:近畿ブロック] [126/138] OK: 伊東 信久\n",
            "[prop:近畿ブロック] [127/138] OK: 一谷 勇一郎\n",
            "[prop:近畿ブロック] [128/138] OK: 阿部 圭史\n",
            "[prop:近畿ブロック] [129/138] OK: 和田 有一朗\n",
            "[prop:近畿ブロック] [130/138] OK: 遠藤 良太\n",
            "[prop:近畿ブロック] [131/138] OK: 市村 浩一郎\n",
            "[prop:近畿ブロック] [132/138] OK: 三木 圭恵\n",
            "[prop:近畿ブロック] [133/138] OK: 徳安 淳子\n",
            "[prop:近畿ブロック] [134/138] OK: 掘井 健智\n",
            "[prop:近畿ブロック] [135/138] OK: 住吉 寛紀\n",
            "[prop:近畿ブロック] [136/138] OK: 池畑 浩太朗\n",
            "[prop:近畿ブロック] [137/138] OK: 浦平 美博\n",
            "[prop:近畿ブロック] [138/138] OK: 奥野 卓志\n"
          ]
        }
      ]
    }
  ]
}